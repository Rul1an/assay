<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="The purity test for AI — Zero-flake CI for AI agents"><meta name=author content="Assay Team"><link href=https://docs.assay.dev/PERFORMANCE-ASSESSMENT/ rel=canonical><link rel=icon href=../assets/logo.svg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.28"><title>Performance Assessment — Wat je nodig hebt om performance kritisch te beoordelen - Assay</title><link rel=stylesheet href=../assets/stylesheets/main.6543a935.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-XXXXXXXXXX",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=green> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#performance-assessment-wat-je-nodig-hebt-om-performance-kritisch-te-beoordelen class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=Assay class="md-header__button md-logo" aria-label=Assay data-md-component=logo> <img src=../assets/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Assay </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Performance Assessment — Wat je nodig hebt om performance kritisch te beoordelen </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=green aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=green aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/Rul1an/assay title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> Rul1an/assay </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../getting-started/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../concepts/ class=md-tabs__link> Core Concepts </a> </li> <li class=md-tabs__item> <a href=../python-sdk/ class=md-tabs__link> Python SDK </a> </li> <li class=md-tabs__item> <a href=../mcp/ class=md-tabs__link> MCP Integration </a> </li> <li class=md-tabs__item> <a href=../reference/config/ class=md-tabs__link> Configuration </a> </li> <li class=md-tabs__item> <a href=../reference/cli/ class=md-tabs__link> CLI Reference </a> </li> <li class=md-tabs__item> <a href=../metrics/ class=md-tabs__link> Metrics Reference </a> </li> <li class=md-tabs__item> <a href=../use-cases/ class=md-tabs__link> Use Cases </a> </li> <li class=md-tabs__item> <a href=../guides/ class=md-tabs__link> Guides </a> </li> <li class=md-tabs__item> <a href=../architecture/ class=md-tabs__link> Architecture </a> </li> <li class=md-tabs__item> <a href=../contributing/ class=md-tabs__link> Contributing </a> </li> <li class=md-tabs__item> <a href=../guides/troubleshooting/ class=md-tabs__link> Troubleshooting </a> </li> <li class=md-tabs__item> <a href=../changelog/ class=md-tabs__link> Changelog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=Assay class="md-nav__button md-logo" aria-label=Assay data-md-component=logo> <img src=../assets/logo.svg alt=logo> </a> Assay </label> <div class=md-nav__source> <a href=https://github.com/Rul1an/assay title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> Rul1an/assay </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=../getting-started/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../getting-started/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../getting-started/first-test/ class=md-nav__link> <span class=md-ellipsis> Your First Test </span> </a> </li> <li class=md-nav__item> <a href=../getting-started/ci-integration/ class=md-nav__link> <span class=md-ellipsis> CI Integration </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Core Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Core Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../concepts/ class=md-nav__link> <span class=md-ellipsis> Core Concepts </span> </a> </li> <li class=md-nav__item> <a href=../concepts/traces/ class=md-nav__link> <span class=md-ellipsis> Traces </span> </a> </li> <li class=md-nav__item> <a href=../concepts/policies/ class=md-nav__link> <span class=md-ellipsis> Policies </span> </a> </li> <li class=md-nav__item> <a href=../concepts/metrics/ class=md-nav__link> <span class=md-ellipsis> Metrics </span> </a> </li> <li class=md-nav__item> <a href=../concepts/replay/ class=md-nav__link> <span class=md-ellipsis> Replay Engine </span> </a> </li> <li class=md-nav__item> <a href=../concepts/cache/ class=md-nav__link> <span class=md-ellipsis> Cache & Fingerprints </span> </a> </li> <li class=md-nav__item> <a href=../concepts/scope/ class=md-nav__link> <span class=md-ellipsis> Scope & Boundaries </span> </a> </li> <li class=md-nav__item> <a href=../concepts/fail-safe/ class=md-nav__link> <span class=md-ellipsis> Fail-Safe Config </span> </a> </li> <li class=md-nav__item> <a href=../concepts/pack-registry/ class=md-nav__link> <span class=md-ellipsis> Pack Registry </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Python SDK </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Python SDK </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../python-sdk/ class=md-nav__link> <span class=md-ellipsis> Python SDK </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> MCP Integration </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> MCP Integration </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../mcp/ class=md-nav__link> <span class=md-ellipsis> MCP Integration </span> </a> </li> <li class=md-nav__item> <a href=../mcp/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../mcp/import-formats/ class=md-nav__link> <span class=md-ellipsis> Import Formats </span> </a> </li> <li class=md-nav__item> <a href=../mcp/server/ class=md-nav__link> <span class=md-ellipsis> Assay MCP Server </span> </a> </li> <li class=md-nav__item> <a href=../mcp/self-correction/ class=md-nav__link> <span class=md-ellipsis> Self-Correcting Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Configuration </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Configuration </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../reference/config/ class=md-nav__link> <span class=md-ellipsis> Configuration </span> </a> </li> <li class=md-nav__item> <a href=../reference/config/eval-yaml/ class=md-nav__link> <span class=md-ellipsis> mcp-eval.yaml </span> </a> </li> <li class=md-nav__item> <a href=../reference/config/policies/ class=md-nav__link> <span class=md-ellipsis> Policy Files </span> </a> </li> <li class=md-nav__item> <a href=../reference/sandbox-policies/ class=md-nav__link> <span class=md-ellipsis> Sandbox Policies </span> </a> </li> <li class=md-nav__item> <a href=../reference/sandbox-env/ class=md-nav__link> <span class=md-ellipsis> Environment Filtering </span> </a> </li> <li class=md-nav__item> <a href=../reference/config/sequences/ class=md-nav__link> <span class=md-ellipsis> Sequence Rules DSL </span> </a> </li> <li class=md-nav__item> <a href=../reference/config/migration/ class=md-nav__link> <span class=md-ellipsis> Migration Guide </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> CLI Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> CLI Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../reference/cli/ class=md-nav__link> <span class=md-ellipsis> CLI Reference </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/init/ class=md-nav__link> <span class=md-ellipsis> assay init </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/validate/ class=md-nav__link> <span class=md-ellipsis> assay validate </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/run/ class=md-nav__link> <span class=md-ellipsis> assay run </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/generate/ class=md-nav__link> <span class=md-ellipsis> assay generate </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/explain/ class=md-nav__link> <span class=md-ellipsis> assay explain </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/doctor/ class=md-nav__link> <span class=md-ellipsis> assay doctor </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/watch/ class=md-nav__link> <span class=md-ellipsis> assay watch </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/sandbox/ class=md-nav__link> <span class=md-ellipsis> assay sandbox </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/import/ class=md-nav__link> <span class=md-ellipsis> assay import </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/migrate/ class=md-nav__link> <span class=md-ellipsis> assay migrate </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/replay/ class=md-nav__link> <span class=md-ellipsis> assay replay </span> </a> </li> <li class=md-nav__item> <a href=../reference/cli/mcp-server/ class=md-nav__link> <span class=md-ellipsis> assay mcp-server </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Metrics Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Metrics Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../metrics/ class=md-nav__link> <span class=md-ellipsis> Assertion Types (V1) </span> </a> </li> <li class=md-nav__item> <a href=../metrics/args-valid/ class=md-nav__link> <span class=md-ellipsis> args_valid </span> </a> </li> <li class=md-nav__item> <a href=../metrics/sequence-valid/ class=md-nav__link> <span class=md-ellipsis> sequence_valid </span> </a> </li> <li class=md-nav__item> <a href=../metrics/tool-blocklist/ class=md-nav__link> <span class=md-ellipsis> tool_blocklist </span> </a> </li> <li class=md-nav__item> <a href=../metrics/custom/ class=md-nav__link> <span class=md-ellipsis> Custom Metrics </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_9> <label class=md-nav__link for=__nav_9 id=__nav_9_label tabindex=0> <span class=md-ellipsis> Use Cases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_9_label aria-expanded=false> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> Use Cases </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../use-cases/ class=md-nav__link> <span class=md-ellipsis> Use Cases </span> </a> </li> <li class=md-nav__item> <a href=../use-cases/ci-gate/ class=md-nav__link> <span class=md-ellipsis> CI Regression Gate </span> </a> </li> <li class=md-nav__item> <a href=../use-cases/debugging/ class=md-nav__link> <span class=md-ellipsis> Trace-Driven Debugging </span> </a> </li> <li class=md-nav__item> <a href=../use-cases/air-gapped/ class=md-nav__link> <span class=md-ellipsis> Air-Gapped Enterprise </span> </a> </li> <li class=md-nav__item> <a href=../use-cases/self-correction/ class=md-nav__link> <span class=md-ellipsis> Agent Self-Correction </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_10> <label class=md-nav__link for=__nav_10 id=__nav_10_label tabindex=0> <span class=md-ellipsis> Guides </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_10_label aria-expanded=false> <label class=md-nav__title for=__nav_10> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../guides/ class=md-nav__link> <span class=md-ellipsis> Guides </span> </a> </li> <li class=md-nav__item> <a href=../guides/sandbox-security/ class=md-nav__link> <span class=md-ellipsis> Sandbox Security </span> </a> </li> <li class=md-nav__item> <a href=../guides/gateway-pattern/ class=md-nav__link> <span class=md-ellipsis> Gateway Pattern </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_11> <label class=md-nav__link for=__nav_11 id=__nav_11_label tabindex=0> <span class=md-ellipsis> Architecture </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_11_label aria-expanded=false> <label class=md-nav__title for=__nav_11> <span class="md-nav__icon md-icon"></span> Architecture </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../architecture/ class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=../architecture/crates/ class=md-nav__link> <span class=md-ellipsis> Crate Structure </span> </a> </li> <li class=md-nav__item> <a href=../architecture/data-flow/ class=md-nav__link> <span class=md-ellipsis> Data Flow </span> </a> </li> <li class=md-nav__item> <a href=../PERFORMANCE-BUDGETS/ class=md-nav__link> <span class=md-ellipsis> Performance Budgets </span> </a> </li> <li class=md-nav__item> <a href=../architecture/adrs/ class=md-nav__link> <span class=md-ellipsis> ADRs </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_12> <label class=md-nav__link for=__nav_12 id=__nav_12_label tabindex=0> <span class=md-ellipsis> Contributing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_12_label aria-expanded=false> <label class=md-nav__title for=__nav_12> <span class="md-nav__icon md-icon"></span> Contributing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../contributing/ class=md-nav__link> <span class=md-ellipsis> Contributing </span> </a> </li> <li class=md-nav__item> <a href=../contributing/setup/ class=md-nav__link> <span class=md-ellipsis> Development Setup </span> </a> </li> <li class=md-nav__item> <a href=../contributing/metrics/ class=md-nav__link> <span class=md-ellipsis> Adding Metrics </span> </a> </li> <li class=md-nav__item> <a href=../contributing/releases/ class=md-nav__link> <span class=md-ellipsis> Release Process </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../guides/troubleshooting/ class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> </li> <li class=md-nav__item> <a href=../changelog/ class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#standaard-toolkit-en-werkwijze-jan-2026 class=md-nav__link> <span class=md-ellipsis> Standaard toolkit en werkwijze (jan 2026) </span> </a> <nav class=md-nav aria-label="Standaard toolkit en werkwijze (jan 2026)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-benchmarks-die-statistisch-kloppen class=md-nav__link> <span class=md-ellipsis> 1) Benchmarks die statistisch kloppen </span> </a> </li> <li class=md-nav__item> <a href=#2-profiling-waar-gaat-de-tijd-heen class=md-nav__link> <span class=md-ellipsis> 2) Profiling: waar gaat de tijd heen </span> </a> </li> <li class=md-nav__item> <a href=#3-sqlite-wal-checkpointing-busy-handling-en-meten class=md-nav__link> <span class=md-ellipsis> 3) SQLite: WAL + checkpointing + busy handling (en meten) </span> </a> </li> <li class=md-nav__item> <a href=#4-ci-caching-en-reproduceerbaarheid-warm-cache-voelt-gratis class=md-nav__link> <span class=md-ellipsis> 4) CI-caching en reproduceerbaarheid (warm cache “voelt gratis”) </span> </a> </li> <li class=md-nav__item> <a href=#5-instrumentatie-phase-timings-en-async-inzicht class=md-nav__link> <span class=md-ellipsis> 5) Instrumentatie: phase timings en async-inzicht </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#minimum-sota-voor-deze-context class=md-nav__link> <span class=md-ellipsis> Minimum SOTA (voor deze context) </span> </a> </li> <li class=md-nav__item> <a href=#realisme-wat-de-huidige-setup-wel-en-niet-meet class=md-nav__link> <span class=md-ellipsis> Realisme: wat de huidige setup wél en níet meet </span> </a> </li> <li class=md-nav__item> <a href=#standard-concurrency-configuration-norm class=md-nav__link> <span class=md-ellipsis> Standard concurrency configuration (norm) </span> </a> </li> <li class=md-nav__item> <a href=#a-reproduceerbare-workloads class=md-nav__link> <span class=md-ellipsis> A. Reproduceerbare workloads </span> </a> <nav class=md-nav aria-label="A. Reproduceerbare workloads"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#wat-je-nodig-hebt class=md-nav__link> <span class=md-ellipsis> Wat je nodig hebt </span> </a> </li> <li class=md-nav__item> <a href=#workload-generator-deterministisch-en-vergelijkbaar class=md-nav__link> <span class=md-ellipsis> Workload-generator: deterministisch en vergelijkbaar </span> </a> </li> <li class=md-nav__item> <a href=#huidige-stand-inventaris class=md-nav__link> <span class=md-ellipsis> Huidige stand (inventaris) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#b-metingen-first-class-niet-optioneel class=md-nav__link> <span class=md-ellipsis> B. Metingen: first-class, niet optioneel </span> </a> <nav class=md-nav aria-label="B. Metingen: first-class, niet optioneel"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#minimale-set-die-je-nodig-hebt class=md-nav__link> <span class=md-ellipsis> Minimale set die je nodig hebt </span> </a> </li> <li class=md-nav__item> <a href=#huidige-stand-inventaris_1 class=md-nav__link> <span class=md-ellipsis> Huidige stand (inventaris) </span> </a> </li> <li class=md-nav__item> <a href=#vereiste-outputvelden-summaryjson-voor-regressie-gate class=md-nav__link> <span class=md-ellipsis> Vereiste outputvelden (summary.json) — voor regressie-gate </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sqlite-contention-observability-must-have-voor-p03 class=md-nav__link> <span class=md-ellipsis> SQLite-contention observability (must-have voor P0.3) </span> </a> <nav class=md-nav aria-label="SQLite-contention observability (must-have voor P0.3)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#a-busylocked-tellen-en-verklaren class=md-nav__link> <span class=md-ellipsis> A) Busy/locked: tellen én verklaren </span> </a> </li> <li class=md-nav__item> <a href=#b-wal-checkpointing-anders-worden-p95-spikes-mystery-meat class=md-nav__link> <span class=md-ellipsis> B) WAL checkpointing: anders worden p95-spikes “mystery meat” </span> </a> </li> <li class=md-nav__item> <a href=#busy-handler-en-checkpoint-nuance-voor-reviewers class=md-nav__link> <span class=md-ellipsis> Busy handler en checkpoint: nuance voor reviewers </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#concurrency-matrix-standaard-config-varianten class=md-nav__link> <span class=md-ellipsis> Concurrency-matrix (standaard config × varianten) </span> </a> </li> <li class=md-nav__item> <a href=#ci-realiteit-cache-persistence-bewijs class=md-nav__link> <span class=md-ellipsis> CI-realiteit: cache persistence + bewijs </span> </a> </li> <li class=md-nav__item> <a href=#profiling-1-doorslaggevend-optioneel-maar-vaak-doorslaggevend class=md-nav__link> <span class=md-ellipsis> Profiling (1× doorslaggevend, optioneel maar vaak doorslaggevend) </span> </a> </li> <li class=md-nav__item> <a href=#assessment-checklist-2-3-4-stappen class=md-nav__link> <span class=md-ellipsis> Assessment-checklist (2 / 3 / 4 stappen) </span> </a> </li> <li class=md-nav__item> <a href=#minimum-subset-wat-je-echt-nodig-hebt-om-kritisch-te-reviewen class=md-nav__link> <span class=md-ellipsis> Minimum-subset: wat je écht nodig hebt om kritisch te reviewen </span> </a> </li> <li class=md-nav__item> <a href=#c-ci-realiteit class=md-nav__link> <span class=md-ellipsis> C. CI-realiteit </span> </a> <nav class=md-nav aria-label="C. CI-realiteit"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#cache-in-ci-blessed-snippet class=md-nav__link> <span class=md-ellipsis> Cache in CI: blessed snippet </span> </a> </li> <li class=md-nav__item> <a href=#huidige-stand class=md-nav__link> <span class=md-ellipsis> Huidige stand </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#bench-harness-smoke-vs-authoritative class=md-nav__link> <span class=md-ellipsis> Bench harness: smoke vs authoritative </span> </a> </li> <li class=md-nav__item> <a href=#resultaten-voorbeeld-run class=md-nav__link> <span class=md-ellipsis> Resultaten (voorbeeld run) </span> </a> </li> <li class=md-nav__item> <a href=#kritische-beoordeling-wat-dit-wel-bewijst-en-wat-nog-niet class=md-nav__link> <span class=md-ellipsis> Kritische beoordeling: wat dit wél bewijst en wat nog niet </span> </a> <nav class=md-nav aria-label="Kritische beoordeling: wat dit wél bewijst en wat nog niet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-wat-je-met-deze-run-al-wel-hard-kunt-concluderen class=md-nav__link> <span class=md-ellipsis> 1) Wat je met deze run al wél hard kunt concluderen </span> </a> </li> <li class=md-nav__item> <a href=#2-waar-de-cijfers-nu-wel-en-nog-niet-genoeg-over-zeggen class=md-nav__link> <span class=md-ellipsis> 2) Waar de cijfers nu wél en nog niet genoeg over zeggen </span> </a> </li> <li class=md-nav__item> <a href=#3-realismecheck-zijn-de-getallen-logisch class=md-nav__link> <span class=md-ellipsis> 3) Realismecheck: zijn de getallen logisch? </span> </a> </li> <li class=md-nav__item> <a href=#4-wat-dit-betekent-voor-adr-019-p03-en-wat-nu-implementeren class=md-nav__link> <span class=md-ellipsis> 4) Wat dit betekent voor ADR-019 P0.3 (en wat nu implementeren) </span> </a> </li> <li class=md-nav__item> <a href=#4b-vergelijking-met-sota-2026-advies-writer-queue-batching class=md-nav__link> <span class=md-ellipsis> 4b) Vergelijking met SOTA 2026-advies (writer queue + batching) </span> </a> </li> <li class=md-nav__item> <a href=#5-next-level-verbeteringen-laag-effort class=md-nav__link> <span class=md-ellipsis> 5) Next-level verbeteringen (laag effort) </span> </a> </li> <li class=md-nav__item> <a href=#6-volgende-stappen-hoogste-roi-en-afweging-advies class=md-nav__link> <span class=md-ellipsis> 6) Volgende stappen (hoogste ROI) — en afweging advies </span> </a> </li> <li class=md-nav__item> <a href=#7-perf-gate-wanneer-warn-vs-fail class=md-nav__link> <span class=md-ellipsis> 7) Perf gate: wanneer “warn” vs “fail”? </span> </a> </li> <li class=md-nav__item> <a href=#8-ci-nog-te-borgen class=md-nav__link> <span class=md-ellipsis> 8) CI: nog te borgen </span> </a> </li> <li class=md-nav__item> <a href=#status-metrics-in-code class=md-nav__link> <span class=md-ellipsis> Status metrics in code </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#eindbeoordeling-eerste-review-na-batching class=md-nav__link> <span class=md-ellipsis> Eindbeoordeling (eerste review + na batching) </span> </a> </li> <li class=md-nav__item> <a href=#samenvatting-wat-er-nu-is-vs-wat-er-nog-moet-voor-p03-validatie class=md-nav__link> <span class=md-ellipsis> Samenvatting: wat er nu is vs wat er nog moet (voor P0.3-validatie) </span> </a> </li> <li class=md-nav__item> <a href=#wat-is-nu-echt-open class=md-nav__link> <span class=md-ellipsis> Wat is nú écht open </span> </a> </li> <li class=md-nav__item> <a href=#cleanup-na-assessment class=md-nav__link> <span class=md-ellipsis> Cleanup na assessment </span> </a> </li> <li class=md-nav__item> <a href=#blessed-perf-toolkit-voor-implementatie class=md-nav__link> <span class=md-ellipsis> Blessed perf toolkit (voor implementatie) </span> </a> <nav class=md-nav aria-label="Blessed perf toolkit (voor implementatie)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#criterion-benchmarks-micromeso class=md-nav__link> <span class=md-ellipsis> Criterion-benchmarks (micro/meso) </span> </a> </li> <li class=md-nav__item> <a href=#hyperfine-e2e-blessed-flow class=md-nav__link> <span class=md-ellipsis> Hyperfine e2e: blessed flow </span> </a> </li> <li class=md-nav__item> <a href=#forensic-tail-latency-mode class=md-nav__link> <span class=md-ellipsis> Forensic tail-latency mode </span> </a> </li> <li class=md-nav__item> <a href=#tail-latency-alarm-policy class=md-nav__link> <span class=md-ellipsis> Tail-latency alarm policy </span> </a> </li> <li class=md-nav__item> <a href=#bencher-threshold-mapping class=md-nav__link> <span class=md-ellipsis> Bencher threshold mapping </span> </a> </li> <li class=md-nav__item> <a href=#nightly-forensic-trend class=md-nav__link> <span class=md-ellipsis> Nightly forensic trend </span> </a> </li> <li class=md-nav__item> <a href=#ci-jobs-voor-perf class=md-nav__link> <span class=md-ellipsis> CI-job(s) voor perf </span> </a> </li> <li class=md-nav__item> <a href=#ci-baseline-bencher class=md-nav__link> <span class=md-ellipsis> CI baseline: Bencher </span> </a> <nav class=md-nav aria-label="CI baseline: Bencher"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#bencher-secrets-verkrijgen-en-configureren class=md-nav__link> <span class=md-ellipsis> Bencher secrets verkrijgen en configureren </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#semanticjudge-vcr-workload class=md-nav__link> <span class=md-ellipsis> Semantic/judge VCR-workload </span> </a> </li> <li class=md-nav__item> <a href=#adapter-outputs-criterion-flags-vcr-hygiene class=md-nav__link> <span class=md-ellipsis> Adapter outputs + Criterion flags + VCR hygiene </span> </a> </li> <li class=md-nav__item> <a href=#bencher-ingest-exacte-commands-en-reports class=md-nav__link> <span class=md-ellipsis> Bencher ingest: exacte commands en reports </span> </a> </li> <li class=md-nav__item> <a href=#bencher-policy-reports-warn-vs-fail-thresholds class=md-nav__link> <span class=md-ellipsis> Bencher policy: reports, warn vs fail, thresholds </span> </a> </li> <li class=md-nav__item> <a href=#summaryjson-velden-phase-store class=md-nav__link> <span class=md-ellipsis> summary.json-velden (phase + store) </span> </a> </li> <li class=md-nav__item> <a href=#ci-cache-blessed-snippet class=md-nav__link> <span class=md-ellipsis> CI-cache: blessed snippet </span> </a> </li> <li class=md-nav__item> <a href=#ci-cache-voor-perf-jobs class=md-nav__link> <span class=md-ellipsis> CI cache voor perf jobs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#perf-gate-policy-optioneel class=md-nav__link> <span class=md-ellipsis> Perf gate policy (optioneel) </span> </a> </li> <li class=md-nav__item> <a href=#verwijzingen class=md-nav__link> <span class=md-ellipsis> Verwijzingen </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=performance-assessment-wat-je-nodig-hebt-om-performance-kritisch-te-beoordelen>Performance Assessment — Wat je nodig hebt om performance kritisch te beoordelen<a class=headerlink href=#performance-assessment-wat-je-nodig-hebt-om-performance-kritisch-te-beoordelen title="Permanent link">&para;</a></h1> <p>Dit document beschrijft wat er nodig is om de performance van het Assay PR-gate pad <strong>kritisch te beoordelen</strong> en <strong>ADR-019 P0.3 (Store performance) feitelijk te valideren</strong>. Het Runner → Store (SQLite) → cache → metrics → report pad is de centrale bottleneck; reproduceerbare workloads, <strong>first-class metingen</strong> en CI-realiteit zijn nodig. Zonder file-backed WAL-runs, fase-timings, SQLite-contention-metrics en herhaalde runs (median/p95) blijft het een “smoke timing script”, geen “contention benchmark”.</p> <p><strong>Gerelateerd:</strong> <a href=../architecture/ADR-019-PR-Gate-2026-SOTA/#p03-store-performance-wal--single-writer-batching--bounded-queue>ADR-019 P0.3 Store performance</a>, <a href=../concepts/cache/ >concepts/cache.md</a>, <a href=../REVIEW-MATERIALS/ >REVIEW-MATERIALS</a>.</p> <hr> <h2 id=standaard-toolkit-en-werkwijze-jan-2026>Standaard toolkit en werkwijze (jan 2026)<a class=headerlink href=#standaard-toolkit-en-werkwijze-jan-2026 title="Permanent link">&para;</a></h2> <p>Anno januari 2026 is dit de gangbare toolkit en werkwijze om performance van een Rust/SQLite/CI PR-gate <strong>kritisch te beoordelen</strong>. Micro- en end-to-end metingen worden <strong>apart</strong> gehouden; altijd <strong>median + p95</strong> (niet één run).</p> <h3 id=1-benchmarks-die-statistisch-kloppen>1) Benchmarks die statistisch kloppen<a class=headerlink href=#1-benchmarks-die-statistisch-kloppen title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Tool</th> <th>Doel</th> <th>Best practice</th> </tr> </thead> <tbody> <tr> <td><strong>Criterion.rs</strong></td> <td>Micro/meso benchmarks: store inserts, fingerprinting, report rendering, etc. Bewaart historical data en rapporteert verandering + statistiek.</td> <td>Gebruik voor store/runner-microbench; median + p95; regressie-gate in CI.</td> </tr> <tr> <td><strong>Hyperfine</strong></td> <td>End-to-end CLI-timings (<code>assay ci …</code>) met warmup en outlier-detectie; JSON-output voor trends.</td> <td>Gebruik voor <code>assay ci</code> (of <code>assay run</code>) e2e; warmup runs; median/p95. Integratie met continuous benchmarking (bijv. <a href=https://bencher.dev/ >Bencher</a>) als je regressies in CI wilt gate'en.</td> </tr> </tbody> </table> <p><strong>Regel:</strong> Meet altijd <strong>median + p95</strong>; houd <strong>micro (Criterion)</strong> en <strong>e2e (Hyperfine)</strong> apart.</p> <h3 id=2-profiling-waar-gaat-de-tijd-heen>2) Profiling: waar gaat de tijd heen<a class=headerlink href=#2-profiling-waar-gaat-de-tijd-heen title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Tool</th> <th>Doel</th> <th>Best practice</th> </tr> </thead> <tbody> <tr> <td><strong>perf + flamegraph</strong> (Linux)</td> <td>CPU-bottlenecks; <a href=https://github.com/flamegraph-rs/flamegraph>cargo flamegraph</a>.</td> <td><a href=https://nnethercote.github.io/perf-book/profiling.html>Rust Performance Book</a>: aanbevolen voor CPU.</td> </tr> <tr> <td><strong>Samply</strong></td> <td>Cross-platform sampling profiler met Firefox Profiler UI.</td> <td>Populair alternatief voor niet-Linux of als je Profiler UI wilt.</td> </tr> <tr> <td><strong>tokio-console</strong></td> <td>Async/runtime: tasks, wakers, scheduling.</td> <td>Bij async-issues (store lock, tokio runtime).</td> </tr> </tbody> </table> <p><strong>Regel:</strong> Minstens <strong>1× per kwartaal</strong> (of bij grote refactors) een flamegraph/samply-profile als artefact bij “perf regressie”-tickets.</p> <h3 id=3-sqlite-wal-checkpointing-busy-handling-en-meten>3) SQLite: WAL + checkpointing + busy handling (en meten)<a class=headerlink href=#3-sqlite-wal-checkpointing-busy-handling-en-meten title="Permanent link">&para;</a></h3> <p>Voor het Store-pad (contention, tail latency):</p> <ul> <li><strong>WAL mode</strong> is de basis; <strong>autocheckpoint/checkpoint-strategie</strong> bepaalt spikes en WAL-groei.</li> <li><strong>busy_timeout</strong> en/of busy handler (rusqlite ondersteunt dit); lock contention gecontroleerd afhandelen.</li> <li><strong>PRAGMA’s</strong> zijn de officiële manier om gedrag te configureren en te inspecteren.</li> </ul> <p><strong>Regel:</strong> Naast wall-clock altijd <strong>counters</strong>: sqlite_busy_count, “store lock wait”, batch sizes, en (minimaal) WAL/checkpoint-observability.</p> <h3 id=4-ci-caching-en-reproduceerbaarheid-warm-cache-voelt-gratis>4) CI-caching en reproduceerbaarheid (warm cache “voelt gratis”)<a class=headerlink href=#4-ci-caching-en-reproduceerbaarheid-warm-cache-voelt-gratis title="Permanent link">&para;</a></h3> <ul> <li><strong>actions/cache</strong> met goede <strong>key</strong> + <strong>restore-keys</strong> (near-misses); <a href=https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows>GitHub beschrijft</a> hoe restore-keys gezocht worden.</li> <li>Gebruik de <strong>cache-hit output</strong> om te bewijzen dat een warm-run is uitgevoerd.</li> </ul> <p><strong>Regel:</strong> Eén <strong>blessed snippet</strong> voor <code>.assay/</code> (of relevante subpaths) + invalidatie (hash van eval/policy/trace + assay version).</p> <h3 id=5-instrumentatie-phase-timings-en-async-inzicht>5) Instrumentatie: phase timings en async-inzicht<a class=headerlink href=#5-instrumentatie-phase-timings-en-async-inzicht title="Permanent link">&para;</a></h3> <ul> <li><strong>tracing</strong> + tooling (en voor async: <strong>tokio-console</strong>) is in Rust de standaard om runtime-gedrag te begrijpen zonder meteen zware profilers.</li> <li><strong>Phase-timings</strong> (ingest_ms, run_suite_ms, report_ms, etc.) als <strong>vaste velden in summary.json</strong> → CI-runs onderling vergelijken en regressies automatisch detecteren.</li> </ul> <hr> <h2 id=minimum-sota-voor-deze-context>Minimum SOTA (voor deze context)<a class=headerlink href=#minimum-sota-voor-deze-context title="Permanent link">&para;</a></h2> <p>Wat als <strong>minimum SOTA</strong> geldt om performance echt te kunnen reviewen en regressies te gate'en:</p> <ol> <li><strong>Criterion</strong> voor store/runner-microbench + <strong>Hyperfine</strong> voor <code>assay ci</code> (of <code>assay run</code>) end-to-end; beide met <strong>median/p95</strong>.</li> <li>Minstens één van: <strong>perf/flamegraph</strong> of <strong>samply</strong>; voor async: <strong>tokio-console</strong>.</li> <li><strong>SQLite:</strong> WAL + checkpointing + busy_timeout <strong>én</strong> meten van contention-counters (sqlite_busy_count, store_wait_ms, etc.).</li> <li><strong>CI:</strong> actions/cache met <strong>key</strong> + <strong>restore-keys</strong> + <strong>cache-hit bewijs</strong>.</li> </ol> <hr> <h2 id=realisme-wat-de-huidige-setup-wel-en-niet-meet>Realisme: wat de huidige setup wél en níet meet<a class=headerlink href=#realisme-wat-de-huidige-setup-wel-en-niet-meet title="Permanent link">&para;</a></h2> <ul> <li><strong>Wat het nu vooral meet:</strong> CLI/startup/parse/report overhead. Dat medium (30 tests) en large (50 tests) ongeveer dezelfde wall-clock geven (~37 ms) is een rode vlag: de workload per test doet nauwelijks extra werk en er is te weinig schrijfvolume om lock/contention te laten zien.</li> <li><strong>Wat het doel moet zijn voor P0.3:</strong> SQLite write contention onder parallel runs — dus <strong>veel writes</strong> (result rows, steps, tool_calls, metrics) en <strong>file-backed DB met WAL</strong>, niet alleen <code>:memory:</code>.</li> <li><strong><code>:memory:</code>:</strong> Prima als <strong>CPU-only baseline</strong>; je ziet er geen realistische WAL/checkpoint/IO-effecten mee. De <strong>hoofdmeting</strong> voor P0.3 moet een <strong>file-backed DB op disk</strong> (of tmpfs voor CI-stabiliteit) zijn, want daar laten WAL/checkpoint en IO zien waar het pijn doet. <strong>File-backed DB runs zijn “primary truth”</strong>, :memory: alleen als baseline.</li> <li><strong>Eén run per scenario:</strong> Te ruisgevoelig; scheduling variance kan groter zijn dan de verschillen. <strong>Minimaal:</strong> 10–30 runs per scenario → rapporteer <strong>median + p95</strong> (en liefst stddev); of gebruik een harness (bijv. Criterion) dat dit automatisch doet. <strong>E2E herhaalruns</strong> moeten echt gebeuren voor: worstcase file-backed WAL, en standaard concurrency (parallel=4) + varianten (&#8539;/16), zodat p95’s niet “toevallig” door jitter zijn.</li> </ul> <hr> <h2 id=standard-concurrency-configuration-norm>Standard concurrency configuration (norm)<a class=headerlink href=#standard-concurrency-configuration-norm title="Permanent link">&para;</a></h2> <p>Om “sqlite_busy_count == 0” en p95-budgets eenduidig te maken, moet de <strong>standaard concurrency-configuratie</strong> hard gedefinieerd zijn:</p> <table> <thead> <tr> <th>Onderdeel</th> <th>Norm</th> </tr> </thead> <tbody> <tr> <td><strong>Runner</strong></td> <td><code>parallel = 4</code> (semaphore in <code>run_suite</code>).</td> </tr> <tr> <td><strong>Store</strong></td> <td>Single writer queue (zodra P0.3 geïmplementeerd); geen externe concurrent writers op dezelfde DB.</td> </tr> <tr> <td><strong>DB</strong></td> <td>WAL aan + checkpoint policy (bijv. wal_autocheckpoint); <strong>busy handling</strong> via onze custom busy handler (geen PRAGMA busy_timeout; zie sectie “Busy handler en checkpoint”).</td> </tr> <tr> <td><strong>WAL / writes</strong></td> <td><strong>BEGIN IMMEDIATE</strong> voor write-transacties (niet DEFERRED), om “read→write upgrade” en SQLITE_BUSY te vermijden.</td> </tr> </tbody> </table> <p>Dit hoort óók in het performance-assessment: meten <strong>vóór/na</strong> writer-queue-refactor (sqlite_busy_count, p95). Zonder baseline vóór de refactor kun je niet bewijzen dat batching/queue tail spikes oplost.</p> <hr> <h2 id=a-reproduceerbare-workloads>A. Reproduceerbare workloads<a class=headerlink href=#a-reproduceerbare-workloads title="Permanent link">&para;</a></h2> <h3 id=wat-je-nodig-hebt>Wat je nodig hebt<a class=headerlink href=#wat-je-nodig-hebt title="Permanent link">&para;</a></h3> <ol> <li><strong>2–3 representatieve trace sets</strong> (klein / gemiddeld / groot) + bijbehorende eval (+ policy waar nodig).</li> <li><strong>Twee kritische workload-typen</strong> (acceptatievoorwaarde voor “kritisch beoordelen”):</li> <li><strong>Deterministic-only store stress</strong> — Alleen deterministische checks (regex, schema, args_valid, sequence); <strong>geen</strong> embeddings/judge I/O. Doel: zuivere store/runner contention.</li> <li><strong>Semantic/judge workload zonder netwerkflakiness</strong> — Cache- en precompute-gedrag meten, zonder internet/LLM-variatie. Praktisch: mock provider of <strong>recorded responses (VCR)</strong> zodat dezelfde inputs dezelfde outputs geven.</li> <li><strong>Eén echte worst-case</strong> — Niet “veel tests” alleen, maar <strong>veel writes</strong>: veel tool_calls per episode, <strong>grote payloads</strong> (args/result), veel result-inserts. Doel: store stress en lock/contention zichtbaar maken.</li> </ol> <p><strong>Waarom:</strong> Zonder die splitsing meet je “alles door elkaar” en kun je bottlenecks niet isoleren.</p> <h3 id=workload-generator-deterministisch-en-vergelijkbaar>Workload-generator: deterministisch en vergelijkbaar<a class=headerlink href=#workload-generator-deterministisch-en-vergelijkbaar title="Permanent link">&para;</a></h3> <ul> <li><strong>Vaste seed en vaste sizes</strong> voor medium/large/worst-case, zodat runs en trends vergelijkbaar blijven (en regressies herhaalbaar zijn).</li> </ul> <h3 id=huidige-stand-inventaris>Huidige stand (inventaris)<a class=headerlink href=#huidige-stand-inventaris title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Workload / Set</th> <th>Locatie</th> <th>Grootte</th> <th>Status</th> <th>Opmerking</th> </tr> </thead> <tbody> <tr> <td>Perf small</td> <td><code>tests/fixtures/perf/</code></td> <td>5 episodes, 5 tests</td> <td>✅</td> <td>Commit; script gebruikt dit.</td> </tr> <tr> <td>Perf medium/large</td> <td>Gegenereerd in temp door <code>scripts/perf_assess.sh</code></td> <td>30 / 50 episodes</td> <td>✅</td> <td>Script; file-backed run in script.</td> </tr> <tr> <td>Worst-case (deterministic store stress)</td> <td><code>scripts/perf_assess.sh</code></td> <td>12×8 tool_calls, ~400B payload</td> <td>✅</td> <td>20× file-backed + parallel matrix; Criterion suite_run_worstcase.</td> </tr> <tr> <td>Golden, CI smoke, examples</td> <td>Zie eerder in doc</td> <td>Klein</td> <td>✅</td> <td>Geen store-stress; referentie.</td> </tr> <tr> <td><strong>Semantic/judge zonder netwerk</strong></td> <td><code>tests/fixtures/perf/semantic_vcr/</code></td> <td>2 tests</td> <td><strong>Fixture ✅</strong></td> <td>VCR/mock nodig voor precompute_ms + cache gedrag; zie “Wat is nú écht open”.</td> </tr> </tbody> </table> <p><strong>Nog open:</strong> <strong>(1)</strong> Semantic/judge workload met VCR of mock (recorded responses), zodat precompute_ms en cache gedrag voor embeddings/judge meetbaar worden zonder LLM-variatie. <strong>(2)</strong> Optioneel: vaste seed/sizes in de generator voor strikte reproduceerbaarheid.</p> <hr> <h2 id=b-metingen-first-class-niet-optioneel>B. Metingen: first-class, niet optioneel<a class=headerlink href=#b-metingen-first-class-niet-optioneel title="Permanent link">&para;</a></h2> <p>Fase-timings en SQLite-contention-counters zijn <strong>niet optioneel</strong> als je P0.3 wilt valideren; anders blijft het interpretatie op gevoel. Ze moeten <strong>first-class outputs</strong> worden (bijv. in summary.json en/of bench-output).</p> <h3 id=minimale-set-die-je-nodig-hebt>Minimale set die je nodig hebt<a class=headerlink href=#minimale-set-die-je-nodig-hebt title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Categorie</th> <th>Velden / metingen</th> </tr> </thead> <tbody> <tr> <td><strong>Fases</strong></td> <td>ingest_ms, precompute_ms, run_suite_ms, report_ms, total_ms</td> </tr> <tr> <td><strong>Store</strong></td> <td>store_wait_ms, store_write_ms, sqlite_busy_count, txn_batch_size</td> </tr> <tr> <td><strong>Cache</strong></td> <td>cache_hit_rate, cache_miss_rate</td> </tr> <tr> <td><strong>Concurrency</strong></td> <td>parallel (uit config); busy_timeout expliciet geconfigureerd/gezet in tooling.</td> </tr> </tbody> </table> <ul> <li><strong>busy_timeout:</strong> Moet in tooling expliciet geconfigureerd/gezet worden; rusqlite ondersteunt dit direct.</li> <li><strong>WAL-tuning:</strong> Alleen WAL aanzetten is niet genoeg; <strong>BEGIN IMMEDIATE</strong> voor writes en checkpoint/autocheckpoint gedrag bewust tunen, anders krijg je spikes. Dit hoort in het plan en in het assessment (meten vóór/na).</li> </ul> <h3 id=huidige-stand-inventaris_1>Huidige stand (inventaris)<a class=headerlink href=#huidige-stand-inventaris_1 title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Meting</th> <th>Status</th> <th>Opmerking</th> </tr> </thead> <tbody> <tr> <td>Fase-timings</td> <td>✅ <strong>Ja</strong></td> <td>run.json: ingest_ms, run_suite_ms, report_ms, total_ms (phases).</td> </tr> <tr> <td>store_wait_ms, store_write_ms, sqlite_busy_count</td> <td>✅ <strong>Ja</strong></td> <td>run.json: store_metrics; ook store_wait_pct/store_write_pct.</td> </tr> <tr> <td>effective_pragmas, wal_checkpoint</td> <td>✅ <strong>Ja</strong></td> <td>run.json: effective_pragmas (incl. synchronous_human), wal_checkpoint (PASSIVE).</td> </tr> <tr> <td>cache_hit_rate / cache_miss_rate</td> <td><strong>Deels</strong></td> <td>Per-test cached/skip; niet geaggregeerd als rate in summary.</td> </tr> <tr> <td>Per-test duration</td> <td>✅ <strong>Ja</strong></td> <td>TestResultRow.duration_ms.</td> </tr> <tr> <td>Standard concurrency</td> <td>✅ <strong>Ja</strong></td> <td>parallel=4 standaard; WAL + pragma’s + BEGIN IMMEDIATE gedocumenteerd en geïmplementeerd.</td> </tr> </tbody> </table> <h3 id=vereiste-outputvelden-summaryjson-voor-regressie-gate>Vereiste outputvelden (summary.json) — voor regressie-gate<a class=headerlink href=#vereiste-outputvelden-summaryjson-voor-regressie-gate title="Permanent link">&para;</a></h3> <p>Om dit “regression gateable” te maken, moeten de volgende velden (of equivalent) in <strong>summary.json</strong> (of een dedicated bench-output) komen:</p> <ul> <li><strong>Phases:</strong> ingest_ms, precompute_ms, run_suite_ms, report_ms, total_ms (+ per-test duration en <strong>slowest 5</strong> in console en summary).</li> <li><strong>Store:</strong> store_wait_ms, store_write_ms, sqlite_busy_count, txn_batch_size (indien van toepassing); <strong>WAL/checkpoint:</strong> wal_size of checkpoint_count (minimaal).</li> <li><strong>Cache:</strong> cache_hit_rate, cache_miss_rate (of hit/miss counts).</li> <li><strong>Run context:</strong> <strong>db path + db_mode</strong> (<code>:memory:</code> vs file), parallel, schema_version; <strong>welke pragma’s effectief gezet zijn</strong> (journal_mode, synchronous, busy_timeout, wal_autocheckpoint).</li> </ul> <p>Een exacte JSON-schema-definitie en Criterion-bench-outline (store-only + suite-run) die aansluit op de workloads kunnen in een vervolgstap worden toegevoegd (bijv. in dit doc of in ADR-019/SPEC).</p> <hr> <h2 id=sqlite-contention-observability-must-have-voor-p03>SQLite-contention observability (must-have voor P0.3)<a class=headerlink href=#sqlite-contention-observability-must-have-voor-p03 title="Permanent link">&para;</a></h2> <p>Om ADR-019 P0.3 te valideren zijn <strong>counters en pragma’s</strong> nodig — en niet alleen tellen, ook <strong>verklaren</strong> waarom busy/lock ontstaat.</p> <h3 id=a-busylocked-tellen-en-verklaren>A) Busy/locked: tellen én verklaren<a class=headerlink href=#a-busylocked-tellen-en-verklaren title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Meting</th> <th>Doel</th> </tr> </thead> <tbody> <tr> <td>sqlite_busy_count</td> <td>Aantal keer SQLITE_BUSY / lock wait. <strong>Noodzakelijk</strong>, maar je wilt óók weten <strong>waarom</strong> busy ontstaat.</td> </tr> <tr> <td>store_wait_ms / store_write_ms</td> <td>Tijd wachten op store lock; tijd in write-transactie.</td> </tr> <tr> <td>txn_batch_size</td> <td>Bij batching: aantal ops per commit.</td> </tr> </tbody> </table> <p><strong>Waarom busy:</strong> De klassieker is <strong>read→write “upgrade”</strong> binnen een transactie: je start met een read (DEFERRED) en gaat dan schrijven → SQLITE_BUSY kan optreden, zelfs met timeout. <strong>Mitigatie:</strong> <strong>BEGIN IMMEDIATE</strong> voor write-transacties (niet DEFERRED). Dit moet in tooling expliciet staan; rusqlite heeft een busy_timeout handler en documenteert dat dit de busy handler beïnvloedt — vastleggen in code en in dit doc.</p> <h3 id=b-wal-checkpointing-anders-worden-p95-spikes-mystery-meat>B) WAL checkpointing: anders worden p95-spikes “mystery meat”<a class=headerlink href=#b-wal-checkpointing-anders-worden-p95-spikes-mystery-meat title="Permanent link">&para;</a></h3> <p>SQLite waarschuwt dat WAL-mode en synchronous-keuzes invloed hebben op durability/IO; <code>synchronous=NORMAL</code> is in WAL vaak “enough” als je die trade-off accepteert. De echte <strong>p95/p99 killers</strong> in file-backed WAL runs zijn vaak <strong>autocheckpoints / checkpoints</strong> (spikes). Daarom minimaal:</p> <ul> <li><strong>wal_autocheckpoint</strong> expliciet zetten <strong>en</strong> loggen;</li> <li><strong>checkpoint events/tellingen</strong> of <strong>WAL size</strong> loggen;</li> <li>in de benchmark “worstcase” <strong>genoeg writes</strong> genereren zodat checkpointing echt gebeurt.</li> </ul> <p><strong>Pragma’s — exact vastleggen wat gezet wordt en in output tonen:</strong></p> <table> <thead> <tr> <th>Pragma</th> <th>Waarde</th> <th>Reden</th> </tr> </thead> <tbody> <tr> <td>journal_mode</td> <td>WAL</td> <td>Concurrent reads tijdens write; minder lock contention.</td> </tr> <tr> <td>synchronous</td> <td>NORMAL</td> <td>Balans durability vs IO; documenteer trade-off.</td> </tr> <tr> <td>busy_timeout</td> <td>Gezet (ms)</td> <td>Rusqlite ondersteunt dit; expliciet zetten in tooling.</td> </tr> <tr> <td>wal_autocheckpoint</td> <td>Gezet (pagina’s)</td> <td>Anders groeit WAL; checkpoint spikes domineren p95.</td> </tr> </tbody> </table> <p><strong>Cruciaal:</strong> Writes met <strong>BEGIN IMMEDIATE</strong> (niet DEFERRED). In output: <strong>db path + db_mode</strong> (<code>:memory:</code> vs file), plus <strong>welke pragma’s effectief gezet zijn</strong> (journal_mode, synchronous, wal_autocheckpoint; busy handling zie hieronder).</p> <h3 id=busy-handler-en-checkpoint-nuance-voor-reviewers>Busy handler en checkpoint: nuance voor reviewers<a class=headerlink href=#busy-handler-en-checkpoint-nuance-voor-reviewers title="Permanent link">&para;</a></h3> <p>SQLite staat maar <strong>één</strong> busy-handling mechanisme per connection toe: ofwel <strong>PRAGMA busy_timeout</strong>, ofwel een <strong>custom busy_handler</strong> (rusqlite: <code>connection.busy_handler()</code>). Als je een custom handler zet, <strong>overschrijft</strong> die de PRAGMA; een later uitgelezen <code>PRAGMA busy_timeout</code> kan dan <strong>0</strong> teruggeven, ook al wacht je in de handler wel degelijk (met backoff/timeout). Daarom: als je een custom handler gebruikt, <strong>niet</strong> op de PRAGMA-waarde vertrouwen voor “is busy handling aan?” — log in plaats daarvan <strong>eigen config</strong> (bijv. <code>busy_timeout_configured_ms</code>).</p> <p><strong>Checkpoint-koppeling:</strong> Tijdens een WAL-checkpoint kunnen andere connections tijdelijk SQLITE_BUSY zien. Als de busy handler <strong>te vroeg</strong> stopt (korte timeout of weinig retries), kan de checkpoint zelf ook SQLITE_BUSY terugkrijgen of blokkeren. Daarom is “busy handler + checkpoint”-gedrag samen relevant voor p95: een handler die netjes wacht (backoff + voldoende timeout) voorkomt spurious failures; te agressief afbreken kan checkpoint-spikes verergeren.</p> <p><strong>Onze keuze:</strong> We gebruiken <strong>één</strong> custom busy handler (tellen + exponential backoff + geconfigureerde timeout). We zetten <strong>geen</strong> PRAGMA busy_timeout, om conflict te vermijden. In run.json loggen we <strong>effective_pragmas.busy_timeout</strong> (kan 0 zijn) én in de code/CLI <strong>busy_timeout_configured_ms</strong> (de timeout die onze handler gebruikt). Zo ziet een reviewer dat busy handling actief is ook als PRAGMA 0 teruggeeft.</p> <hr> <h2 id=concurrency-matrix-standaard-config-varianten>Concurrency-matrix (standaard config × varianten)<a class=headerlink href=#concurrency-matrix-standaard-config-varianten title="Permanent link">&para;</a></h2> <p>Naast de <strong>standaard config</strong> (parallel=4, file-backed WAL, cache off/on) is een <strong>matrix</strong> nodig om te zien waar het knikt:</p> <table> <thead> <tr> <th>parallel</th> <th>DB mode</th> <th>cache</th> <th>Output</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>memory</td> <td>off</td> <td>median, p95, sqlite_busy_count</td> </tr> <tr> <td>4</td> <td>memory</td> <td>off</td> <td>idem</td> </tr> <tr> <td>8</td> <td>memory</td> <td>off</td> <td>idem</td> </tr> <tr> <td>16</td> <td>memory</td> <td>off</td> <td>idem</td> </tr> <tr> <td>1</td> <td>file-backed WAL</td> <td>off</td> <td>idem</td> </tr> <tr> <td>4</td> <td>file-backed WAL</td> <td>off</td> <td>idem</td> </tr> <tr> <td>8</td> <td>file-backed WAL</td> <td>off</td> <td>idem</td> </tr> <tr> <td>16</td> <td>file-backed WAL</td> <td>off</td> <td>idem</td> </tr> <tr> <td>4</td> <td>file-backed WAL</td> <td>on</td> <td>idem (warm cache)</td> </tr> </tbody> </table> <p>Per cel: <strong>20–30 herhalingen</strong> → median + p95 (+ sqlite_busy_count). Dan zie je exact bij welke parallel/DB-mode de tail oploopt.</p> <hr> <h2 id=ci-realiteit-cache-persistence-bewijs>CI-realiteit: cache persistence + bewijs<a class=headerlink href=#ci-realiteit-cache-persistence-bewijs title="Permanent link">&para;</a></h2> <ul> <li><strong>Blessed GitHub Actions cache-snippet</strong> voor <code>.assay/</code> (of subpaths) met <strong>key</strong> + <strong>restore-keys</strong>; documenteer <strong>exact</strong> wat je cached (.assay/ of subsets), welke key/restore-keys je gebruikt. <a href=https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows>GitHub beschrijft restore-keys gedrag expliciet</a>.</li> <li><strong>Bewijs van cache-hit:</strong> Als je “warm cache feels free” claimt, moet je in CI <strong>bewijs leveren via cache-hit</strong>. <code>actions/cache</code> heeft een <strong>cache-hit</strong> output die je in job summary kunt tonen. <strong>Minimaal:</strong> in CI logs een regel <strong><code>cache-hit=true</code></strong> of <strong><code>cache-hit=false</code></strong> (bijv. <code>echo "cache-hit=${{ steps.cache.outputs.cache-hit }}"</code>).</li> </ul> <hr> <h2 id=profiling-1-doorslaggevend-optioneel-maar-vaak-doorslaggevend>Profiling (1× doorslaggevend, optioneel maar vaak doorslaggevend)<a class=headerlink href=#profiling-1-doorslaggevend-optioneel-maar-vaak-doorslaggevend title="Permanent link">&para;</a></h2> <p>Eén <strong>echte profile-artefact</strong> (flamegraph of profielrun) die laat zien waar de tijd zit:</p> <ul> <li><strong>SQLite lock/wait</strong></li> <li><strong>serde/json parsing</strong></li> <li><strong>hashing/fingerprinting</strong></li> <li><strong>report rendering</strong></li> </ul> <p>Dit hoeft niet elke run, maar wel bij refactors (writer queue, batching, WAL tuning). Eén flamegraph is vaak genoeg om te zeggen waar de bottleneck zit voordat je verder optimaliseert.</p> <hr> <h2 id=assessment-checklist-2-3-4-stappen>Assessment-checklist (2 / 3 / 4 stappen)<a class=headerlink href=#assessment-checklist-2-3-4-stappen title="Permanent link">&para;</a></h2> <p>Minimaal voor <strong>“echt goede assessment”</strong>: 2 stappen — <strong>(1)</strong> concurrency-matrix, <strong>(2)</strong> 20× worstcase draaien en run.json analyseren.</p> <p>Voor <strong>“assessment + CI-bewijs”</strong>: 3 stappen — bovenstaande + <strong>(3)</strong> cache + cache-hit in CI.</p> <p>Voor <strong>“assessment + code-hardening”</strong>: 4 stappen — bovenstaande + <strong>(4)</strong> BEGIN IMMEDIATE in de store (write-transacties; voorkomt read→write upgrade en SQLITE_BUSY).</p> <table> <thead> <tr> <th>Stap</th> <th>Vereiste</th> <th>Status</th> </tr> </thead> <tbody> <tr> <td>1</td> <td><strong>Concurrency-matrix</strong> (parallel &frac14;/8/16 op file-backed worstcase)</td> <td>✅ In script; 5× per parallel, store_metrics geaggregeerd.</td> </tr> <tr> <td>2</td> <td><strong>20× worstcase</strong> draaien + run.json analyseren (median/p95 wall + store_metrics)</td> <td>✅ Script slaat run_1.json … run_20.json op; jq aggregateert store_wait_ms, store_write_ms, sqlite_busy_count, wal_checkpoint.</td> </tr> <tr> <td>3</td> <td><strong>Cache + cache-hit in CI</strong></td> <td>✅ baseline-gate-demo.yml cached .eval/.assay; cache-hit in job summary gelogd.</td> </tr> <tr> <td>4</td> <td><strong>BEGIN IMMEDIATE</strong> in de store (write-transacties)</td> <td>✅ Write-transacties gebruiken <code>TransactionBehavior::Immediate</code>.</td> </tr> </tbody> </table> <hr> <h2 id=minimum-subset-wat-je-echt-nodig-hebt-om-kritisch-te-reviewen>Minimum-subset: wat je écht nodig hebt om kritisch te reviewen<a class=headerlink href=#minimum-subset-wat-je-echt-nodig-hebt-om-kritisch-te-reviewen title="Permanent link">&para;</a></h2> <p>Als je maar <strong>drie extra dingen</strong> geeft, dan deze. Met dit setje kan een reviewer hard zeggen: of SQLite contention de bottleneck is, wat writer-queue/batching/WAL tuning oplevert, en waar de resterende tijd heen gaat.</p> <table> <thead> <tr> <th>#</th> <th>Vereiste</th> <th>Toelichting</th> </tr> </thead> <tbody> <tr> <td>1</td> <td><strong>File-backed WAL worstcase: 20× herhaald</strong> → <strong>median + p95</strong> + (wal/checkpoint info)</td> <td>Niet één run; 20 runs worstcase workload met file-backed DB; rapporteer wal/checkpoint als die gemeten worden.</td> </tr> <tr> <td>2</td> <td><strong>SQLite contention metrics in output</strong></td> <td>store_wait_ms, store_write_ms, sqlite_busy_count, txn_batch_size + <strong>pragma’s gelogd</strong> (journal_mode, synchronous, busy_timeout, wal_autocheckpoint).</td> </tr> <tr> <td>3</td> <td><strong>CI cache bewijs</strong></td> <td>Blessed <strong>actions/cache</strong>-snippet in docs + <strong>cache-hit in job summary</strong> (cache-hit=true/false zichtbaar in CI logs).</td> </tr> </tbody> </table> <p><strong>Huidige stand:</strong> <strong>(1)</strong> Script heeft 20× worstcase file-backed + store_metrics-aggregatie + parallel matrix. <strong>(2)</strong> run.json bevat store_metrics, phases, run_context. <strong>(3)</strong> Blessed snippet in doc; <strong>baseline-gate-demo.yml</strong> gebruikt cache voor examples/baseline-gate/.eval en .assay en logt <strong>cache-hit</strong> in job summary. <strong>(4)</strong> Store gebruikt BEGIN IMMEDIATE voor write-transacties.</p> <hr> <h2 id=c-ci-realiteit>C. CI-realiteit<a class=headerlink href=#c-ci-realiteit title="Permanent link">&para;</a></h2> <h3 id=cache-in-ci-blessed-snippet>Cache in CI: blessed snippet<a class=headerlink href=#cache-in-ci-blessed-snippet title="Permanent link">&para;</a></h3> <ul> <li><strong>Default:</strong> Geen persistente cache tussen jobs (cold).</li> <li><strong>Warm-cache claim:</strong> Als je warm-cache performance wilt claimen, moet er een <strong>blessed snippet</strong> zijn die <code>.assay/</code> (of het relevante deel) cached met duidelijke invalidatie.</li> <li><strong>GitHub cache:</strong> Gebruik <strong>key</strong> + <strong>restore-keys</strong>; documenteer <strong>wat wel</strong> (bijv. path <code>.assay/</code> of <code>~/.assay/store.db</code>) en <strong>wat niet</strong> gecached wordt, en op welke bestanden de key/restore-keys gebaseerd zijn (bijv. <code>hashFiles('**/eval.yaml', '**/policy.yaml', '**/traces/*.jsonl')</code>).</li> </ul> <h3 id=huidige-stand>Huidige stand<a class=headerlink href=#huidige-stand title="Permanent link">&para;</a></h3> <ul> <li><strong>baseline-gate-demo.yml</strong> gebruikt actions/cache voor de baseline-gate .eval/.assay en logt cache-hit in de job summary; blessed snippet staat in dit doc (repo-root en subdir-variant).</li> </ul> <hr> <h2 id=bench-harness-smoke-vs-authoritative>Bench harness: smoke vs authoritative<a class=headerlink href=#bench-harness-smoke-vs-authoritative title="Permanent link">&para;</a></h2> <ul> <li><strong>perf_assess.sh:</strong> Blijft als <strong>DX quick check</strong> (lage drempel, repo blijft schoon). Voor regressies en p95-claims is het geen vervanging: je wilt een tool die herhaalruns doet, outliers detecteert en regressies betrouwbaar rapporteert.</li> <li><strong>Authoritative benchmark (Rust 2026): Criterion.rs</strong> Criterion classificeert outliers en maakt duidelijk hoe “noisy” je meting is. Gebruik <strong>cargo bench</strong> (Criterion) als “authoritative benchmark” voor P0.3 en regressie. In CI kun je p95-rapportage eenvoudiger houden door in bench-output <strong>median + p95</strong> te exporteren; Criterion helpt vooral om de <strong>meetkwaliteit</strong> te bewaken.</li> </ul> <p><strong>Concreet: twee benches toevoegen</strong></p> <table> <thead> <tr> <th>Benchmark</th> <th>Scope</th> <th>Doel</th> </tr> </thead> <tbody> <tr> <td><strong>bench_store_write_heavy</strong></td> <td>Store: insert/txn/batching/queue</td> <td>Write-heavy store stress; median/p95.</td> </tr> <tr> <td><strong>bench_suite_run_worstcase</strong></td> <td>Runner → Store → report, file-backed WAL</td> <td>E2E worstcase met echte WAL/checkpoint; genoeg writes zodat checkpointing gebeurt.</td> </tr> </tbody> </table> <p>Plaats: <code>crates/assay-core/benches/</code> (store) en evt. <code>crates/assay-cli/benches/</code> (suite-run) of één gedeelde <code>benches/</code> onder workspace.</p> <hr> <h2 id=resultaten-voorbeeld-run>Resultaten (voorbeeld run)<a class=headerlink href=#resultaten-voorbeeld-run title="Permanent link">&para;</a></h2> <p><strong>Status:</strong> File-backed WAL-run, concurrency-matrix, store_metrics, phases, wal_checkpoint en BEGIN IMMEDIATE zijn geïmplementeerd en in run.json beschikbaar. Wat er <strong>nu nog écht open</strong> staat, staat in de sectie <a href=#wat-is-nú-écht-open>Wat is nú écht open</a> onderaan dit document.</p> <p>Uitgevoerd met <code>./scripts/perf_assess.sh</code> (van repo root, na <code>cargo build</code>). Het script bevat nu:</p> <ul> <li><strong>File-backed run (20×)</strong> voor small workload → <strong>median + p95</strong> (elke run een verse DB-file).</li> <li><strong>Write-heavy worst-case:</strong> 12 episodes × 8 tool_calls + ~400B payload per call; 12 tests (deterministic-only); run met :memory: en met file-backed DB (inclusief <strong>20×</strong> voor worstcase file-backed → median + p95 + store_metrics-aggregatie als jq aanwezig).</li> <li><strong>Parallel matrix:</strong> worstcase file-backed met parallel 1, 4, 8, 16 (5× per waarde); store_metrics worden per parallel geaggregeerd.</li> </ul> <p><strong>Uitkomst van een concrete run</strong> (dev build, macOS):</p> <table> <thead> <tr> <th>Workload</th> <th>Wall-clock (ms)</th> <th>DB mode</th> </tr> </thead> <tbody> <tr> <td>small_cold</td> <td>522</td> <td>:memory:</td> </tr> <tr> <td>medium_cold (30 tests)</td> <td>32</td> <td>:memory:</td> </tr> <tr> <td>small_file_backed_20x</td> <td><strong>median=51.5, p95=68</strong></td> <td>file (20× fresh)</td> </tr> <tr> <td>large_cold (50 tests)</td> <td>41</td> <td>:memory:</td> </tr> <tr> <td>worst_cold_memory</td> <td>35</td> <td>:memory:</td> </tr> <tr> <td><strong>worst_file_backed_20x</strong></td> <td><strong>median=79.5, p95=95</strong></td> <td>file (20× fresh)</td> </tr> <tr> <td>worst_file_backed_1x</td> <td>84</td> <td>file</td> </tr> <tr> <td>small_warm_run1</td> <td>51</td> <td>file (zelfde DB)</td> </tr> <tr> <td>small_warm_run2</td> <td>32</td> <td>file (zelfde DB)</td> </tr> </tbody> </table> <p><em>Opmerking: small_cold (522 ms) is de eerste run en waarschijnlijk cold start; volgende :memory:-runs zijn 32–41 ms.</em></p> <p><strong>20× worstcase + store_metrics (voorbeeld):</strong> worst_file_backed_20x → median ~44 ms, p95 ~60–101 ms; store_wait_ms median 11, p95 13–23; store_write_ms median 4–5; sqlite_busy_count 0; wal_checkpoint.log_frames median 141.</p> <p><strong>Parallel matrix (voorbeeld):</strong> worstcase file-backed, 5× per parallel:</p> <table> <thead> <tr> <th>parallel</th> <th>wall median (ms)</th> <th>wall p95 (ms)</th> <th>store_wait_ms median</th> <th>store_wait_ms p95</th> <th>sqlite_busy_count</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>37</td> <td>43</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <td>4</td> <td>35</td> <td>40</td> <td>11</td> <td>12</td> <td>0</td> </tr> <tr> <td>8</td> <td>32</td> <td>37</td> <td>20</td> <td>23</td> <td>0</td> </tr> <tr> <td>16</td> <td>46</td> <td>50</td> <td>27</td> <td>28</td> <td>0</td> </tr> </tbody> </table> <p><strong>Conclusie (aangescherpt):</strong> De P0.3-bottleneck is de <strong>Store lock-wacht (Mutex contention)</strong> door parallelle test execution; SQLite zelf is niet “busy” (sqlite_busy_count blijft 0), dus we moeten vooral de <strong>app-level write-path serialisatie</strong> verminderen via batching en een single-writer queue. <strong>WAL/checkpointing</strong> blijft monitoren, maar is op basis van deze workload geen P0; checkpointing kan later alsnog gaan bijten (andere workloads, grotere payloads, andere CI-disks), dus “niet belangrijk” is te absoluut — blijf meten.</p> <p><strong>Wat de data hard laat zien:</strong> (1) Geen SQLite-lock probleem maar een app-level serialisatie probleem: één lock (Mutex) die steeds meer threads laat wachten, terwijl het daadwerkelijke write-werk (~4–5 ms) stabiel blijft. (2) WAL/checkpointing is voor deze workload niet de dominante tail-driver (log_frames median 141, wall p95 in tientallen ms); checkpoint-spikes kunnen p95/p99 later wel domineren bij grotere WALs of lang-open readers.</p> <hr> <h2 id=kritische-beoordeling-wat-dit-wel-bewijst-en-wat-nog-niet>Kritische beoordeling: wat dit wél bewijst en wat nog niet<a class=headerlink href=#kritische-beoordeling-wat-dit-wel-bewijst-en-wat-nog-niet title="Permanent link">&para;</a></h2> <h3 id=1-wat-je-met-deze-run-al-wel-hard-kunt-concluderen>1) Wat je met deze run al wél hard kunt concluderen<a class=headerlink href=#1-wat-je-met-deze-run-al-wel-hard-kunt-concluderen title="Permanent link">&para;</a></h3> <p><strong>A) Bruikbare baseline voor file-backed (de “truth” voor P0.3)</strong></p> <ul> <li><strong>small_file_backed_20x:</strong> median 51.5 ms, p95 68 ms</li> <li><strong>worst_file_backed_20x:</strong> median 79.5 ms, p95 95 ms</li> </ul> <p>Dat is precies wat je nodig hebt om straks objectief te zeggen of “writer queue + batching + WAL tuning” p95 verbetert of verslechtert.</p> <p><strong>B) Cold-start overhead in :memory: is zichtbaar</strong></p> <p>small_cold: 522 ms vs medium/large ~32–41 ms wijst op first-run cold start (binary/page cache, allocators, file I/O voor dependencies, etc.). Daarom is herhaalmeting (median/p95) essentieel — wat nu gedaan is.</p> <p><strong>Praktische consequentie:</strong> Voor perf gates baseer je je op file-backed (warm-ish) runs of op een “steady-state” protocol, niet op een eerste :memory: run.</p> <hr> <h3 id=2-waar-de-cijfers-nu-wel-en-nog-niet-genoeg-over-zeggen>2) Waar de cijfers nu wél en nog niet genoeg over zeggen<a class=headerlink href=#2-waar-de-cijfers-nu-wel-en-nog-niet-genoeg-over-zeggen title="Permanent link">&para;</a></h3> <p><strong>A) Oorzaakdata is er nu:</strong> run.json bevat <strong>store_metrics</strong> (sqlite_busy_count, store_wait_ms, store_write_ms, txn_batch_size, <strong>store_wait_pct</strong> / <strong>store_write_pct</strong> als percentage van total_ms), <strong>effective_pragmas</strong> en <strong>wal_checkpoint</strong> (PASSIVE). Daarmee kun je per run zien of p95 vooral lock wait, write time of checkpoint is.</p> <p><strong>B) Busy handler vs PRAGMA busy_timeout (sanity check):</strong> We gebruiken <strong>één</strong> “counting + sleeping + timeout-aware” busy handler; <strong>geen</strong> PRAGMA busy_timeout, omdat SQLite maar één busy handler per connection toestaat — rusqlite documenteert dat PRAGMA busy_timeout en busy_handler elkaar overschrijven. Daarmee voorkom je verrassingen zodra er later echte concurrency is (meerdere connections/readers of andere tools die een handler zetten). Zie <code>busy_handler</code> / <code>busy_timeout_configured_ms</code> in run.json.</p> <p><strong>C) Concurrency-matrix</strong> is geïmplementeerd (parallel &frac14;/8/16 op worstcase file-backed); zie tabel hierboven.</p> <hr> <h3 id=3-realismecheck-zijn-de-getallen-logisch>3) Realismecheck: zijn de getallen logisch?<a class=headerlink href=#3-realismecheck-zijn-de-getallen-logisch title="Permanent link">&para;</a></h3> <p>Ja — file-backed worstcase is trager dan small (median 79.5 vs 51.5); p95 ligt niet extreem ver van median (95 vs 79.5), wat suggereert dat er nog geen enorme tail-spikes zijn, maar zonder checkpoint/busy-counters weet je dat niet zeker.</p> <p><strong>Large-payload variant:</strong> Het script bevat nu <strong>worst_large_payload</strong> (~8 KB args/result per toolcall, 5× file-backed); daarmee kun je zien of store_write_ms stijgt (serde/page churn) en of checkpointing begint te domineren.</p> <hr> <h3 id=4-wat-dit-betekent-voor-adr-019-p03-en-wat-nu-implementeren>4) Wat dit betekent voor ADR-019 P0.3 (en wat nu implementeren)<a class=headerlink href=#4-wat-dit-betekent-voor-adr-019-p03-en-wat-nu-implementeren title="Permanent link">&para;</a></h3> <ul> <li><strong>Batching geïmplementeerd:</strong> De runner schrijft resultaten niet meer per test (N mutex-acquisities), maar verzamelt alle (row, attempts, output) en roept na de loop <strong>één</strong> <code>store.insert_results_batch(run_id, &amp;collected)</code> aan. Dat is één transactie (BEGIN IMMEDIATE) voor alle resultaten + attempts → minder lock convoy, minder micro-transacties.</li> <li><strong>Parallelism tuning:</strong> matrix laat een knik bij parallel 16 (wall p95 50 ms, wait 27 ms); parallel 8 is nog ok (p95 37). Default parallel=4 is goed; overweeg een “auto clamp” in assay ci (bijv. max op CPU count of DB mode) voor DX (“works fast by default”).</li> <li><strong>Validatie na batching:</strong> Draai <code>./scripts/perf_assess.sh</code> opnieuw (20× worstcase + parallel matrix); als store_wait_ms significant daalt (bijv. parallel 16 wait van 27→&lt;10 ms en wall p95 daalt), dan is P0.3 “opgelost” met harde evidence.</li> </ul> <hr> <h3 id=4b-vergelijking-met-sota-2026-advies-writer-queue-batching>4b) Vergelijking met SOTA 2026-advies (writer queue + batching)<a class=headerlink href=#4b-vergelijking-met-sota-2026-advies-writer-queue-batching title="Permanent link">&para;</a></h3> <p>Het volgende advies is de “best practice” voor SQLite + async Rust + CI gates. Hieronder: hoe onze huidige implementatie daarmee vergelijkt en wat de volgende stap zou zijn.</p> <table> <thead> <tr> <th>Adviespunt</th> <th>Huidige stand</th> <th>Gap / volgende stap</th> </tr> </thead> <tbody> <tr> <td><strong>1. Mentale model</strong></td> <td>SQLite = single-writer; doel = minder contention + minder transacties + voorspelbare latency.</td> <td>✅ Aligned.</td> </tr> <tr> <td><strong>2. Eén writer task, connection ownership, géén Mutex in hot path</strong></td> <td>We gebruiken nog <strong>Mutex&lt;Connection&gt;</strong>; alle writes (inclusief insert_results_batch) gaan via lock_conn_write(). Runner doet “batch aan het einde”, maar er is geen dedicated writer task met een channel.</td> <td><strong>Gap:</strong> Volgende niveau = één writer task die de connection <strong>exclusief</strong> bezit; andere tasks sturen <strong>WriteOp</strong>-berichten via een <strong>bounded</strong> mpsc (backpressure). Geen Mutex in de hot path.</td> </tr> <tr> <td><strong>3. Batching: N ops óf X ms (tuneable) + flush barriers</strong></td> <td>We doen <strong>één batch aan het einde van de run</strong> (alle resultaten in één transactie). Geen “N=200 ops of X=10–25 ms” met timer; geen Flush/Shutdown-berichten.</td> <td><strong>Gap:</strong> Volgende niveau = commit bij buffer ≥ N <strong>of</strong> timer ≥ X ms; Flush (oneshot) aan einde test/suite; Shutdown aan einde run. N/X tuneable (bijv. N=200, X=10–25 ms).</td> </tr> <tr> <td><strong>4. WAL + pragmas + checkpointing bewust</strong></td> <td>WAL, synchronous=NORMAL, wal_autocheckpoint=1000; we meten wal_checkpoint(PASSIVE).</td> <td>✅ In lijn; blijven meten.</td> </tr> <tr> <td><strong>5. Busy handler: één mechanisme</strong></td> <td>Eén custom busy handler (tellen + backoff + timeout); geen PRAGMA busy_timeout.</td> <td>✅ In lijn.</td> </tr> <tr> <td><strong>6. Per-test buffering + ordering</strong></td> <td>We bufferen op <strong>suite-niveau</strong> (verzamelen alle resultaten, één flush na de loop). Geen live DB reads tijdens de run die zichtbare resultaten verwachten.</td> <td>✅ Geen ordering/atomicity-probleem; Flush-barrier is impliciet (einde run).</td> </tr> <tr> <td><strong>7. Succescriteria: queue health</strong></td> <td>We hebben store_wait_ms, store_write_ms, txn_batch_size, phases.</td> <td><strong>Gap:</strong> SOTA 2026 voegt toe: <strong>writer_queue_max_depth</strong>, <strong>writer_flush_count</strong>, <strong>avg_batch_size</strong>, <strong>p95_batch_size</strong> (pas beschikbaar zodra er een echte writer-queue is).</td> </tr> <tr> <td><strong>8. Matrix + payload-variant</strong></td> <td>Parallel &frac14;/8/16 op worstcase file-backed; script heeft <strong>worst_large_payload</strong> (~8 KB).</td> <td>✅ In lijn; matrix opnieuw draaien na batching.</td> </tr> </tbody> </table> <p><strong>Aanbevolen implementatievolgorde (SOTA, hoogste ROI):</strong></p> <ol> <li><strong>Writer owns connection</strong> (geen Mutex in hot path) + <strong>bounded queue</strong> (tokio mpsc; message types: IngestBatch, UpsertResult, Flush(oneshot), Shutdown(oneshot)).</li> <li><strong>Batch commits (N ops of X ms)</strong> + flush barriers; N/X tuneable (start N=200, X=10–25 ms).</li> <li><strong>BEGIN IMMEDIATE</strong> voor write-transacties. → ✅ <strong>Al gedaan.</strong></li> <li><strong>Busy handler</strong> eenduidig (één handler). → ✅ <strong>Al gedaan.</strong></li> <li><strong>Matrix rerun</strong> + run.json vergelijken → claim “P0.3 solved”. → <strong>Volgende stap.</strong></li> </ol> <p><strong>Succescriteria (aanscherping SOTA 2026):</strong></p> <ul> <li><strong>Nu:</strong> store_wait_ms p95 (parallel 16) van 27 ms → &lt;10 ms; wall p95 omlaag. store_write_ms mag iets stijgen (grotere batches); total p95 moet dalen — dat is de gewenste trade.</li> <li><strong>Phases:</strong> We hebben phases (ingest_ms, run_suite_ms, report_ms, total_ms); als store_wait daalt maar report_ms explodeert, zie je dat.</li> <li><strong>Later (met writer-queue):</strong> queue health in run.json: <strong>writer_queue_max_depth</strong>, <strong>writer_flush_count</strong>, <strong>avg_batch_size</strong>, <strong>p95_batch_size</strong>.</li> </ul> <p><strong>Conclusie:</strong> Onze huidige stap (“batch aan het einde” + BEGIN IMMEDIATE + busy handler) vermindert al het aantal transacties en mutex-contention. Voor een <strong>volgende PR</strong> kun je de volledige “writer task + bounded queue + N/X batching” doen en dan <strong>queue health</strong> (depth, flush count, batch sizes) in run.json zetten, zodat je harde before/after-evidence hebt en voldoet aan de SOTA 2026-criteria.</p> <hr> <p><strong>Before/after matrix (na batching):</strong></p> <table> <thead> <tr> <th>Metriek</th> <th>Vóór batching (parallel 16)</th> <th>Na batching (parallel 16)</th> <th>Doel</th> </tr> </thead> <tbody> <tr> <td>store_wait_ms median</td> <td>27</td> <td><strong>3</strong></td> <td>&lt;10 ✅</td> </tr> <tr> <td>store_wait_ms p95</td> <td>28</td> <td><strong>5</strong></td> <td>&lt;10 ✅</td> </tr> <tr> <td>wall p95 (ms)</td> <td>50</td> <td><strong>34</strong></td> <td>omlaag ✅</td> </tr> <tr> <td>worst_file_backed_20x store_wait_ms median</td> <td>11</td> <td><strong>0</strong></td> <td>—</td> </tr> <tr> <td>worst_file_backed_20x store_wait_ms p95</td> <td>13–23</td> <td><strong>2</strong></td> <td>—</td> </tr> </tbody> </table> <p><strong>Conclusie na matrix rerun:</strong> De huidige batching (één insert_results_batch na de loop) volstaat: store_wait_ms bij parallel 16 is van 27→3 ms (median) en 28→5 ms (p95); wall p95 daalt van 50→34 ms. <strong>P0.3 kan als “opgelost” worden geclaimd</strong> met deze evidence. Het volledige advies (writer task + bounded queue + N/X) is optioneel voor een latere PR (queue health metrics, nog voorspelbaardere latency).</p> <hr> <p><strong>P0.3 scope + guardrails (SOTA 2026)</strong></p> <ol> <li> <p><strong>Scope van “opgelost”</strong> — Formuleer in ADR/notes: <strong>Opgelost voor de huidige worstcase workload + parallelmatrix</strong> (zoals gemeten). <strong>Niet universeel bewezen</strong> voor andere workloads (grotere payloads, meerdere readers, CI filesystem jitter). Zo voorkom je dat iemand later een andere workload toevoegt en zegt “maar ADR zei dat het opgelost was”.</p> </li> <li> <p><strong>Writer-queue als contingency, niet als P0</strong> — Houd writer-queue + bounded channel als <strong>backlog/next level</strong>, niet als verplichte volgende stap. Doe die wél zodra: store_wait_ms weer oploopt bij nieuwe suites; meer write-paths (meer tables/rows); meerdere DB consumers (bijv. background ingest / parallel suites). Gebruik een <strong>bounded</strong> mpsc (Tokio’s bounded channel wacht netjes als de buffer vol is); unbounded is een klassieke perf/memory footgun.</p> </li> <li> <p><strong>Batching “production-grade” (volgende niveau)</strong> — Nu: effectief “flush aan het einde”. SOTA is: <strong>commit bij N ops of X ms</strong> (bounded latency) + <strong>Flush barrier (oneshot)</strong> op suite-einde zodat CI deterministisch blijft. Android/SQLite guidance noemt batching in één transactie expliciet; N/X is de gebruikelijke operationalisering voor latency.</p> </li> <li> <p><strong>Busy handler semantiek</strong> — Er kan maar één busy handler per connection zijn; PRAGMA busy_timeout / busy_timeout() overschrijven een custom handler. We hebben gekozen: <strong>één custom busy handler</strong> die tellen + backoff/sleep + timeout implementeert; we loggen <strong>busy_timeout_configured_ms</strong> zelf (niet de PRAGMA-waarde, die 0 kan zijn). Zo blijft de semantics correct en voorkom je verrassingen.</p> </li> <li> <p><strong>Guardrail-metingen (lage moeite, hoge zekerheid)</strong> — Om regressies later niet te missen: <strong>(a)</strong> Queue/batch health (ook zonder writer queue): <strong>avg_batch_size</strong>, <strong>flush_count</strong>, <strong>max_batch_size</strong> in run.json (we hebben al txn_batch_size; uitbreiden met flush_count zodra er meerdere flushes zijn). <strong>(b)</strong> WAL/checkpoint blijft loggen (wal_checkpoint in run.json) zodat je ziet of toekomstige payloads/checkpointing tail-spikes veroorzaken.</p> </li> <li> <p><strong>Succescriteria aanscherping</strong> — Naast “parallel 16 wait &lt;10 ms”: <strong>(1)</strong> <strong>Batching correctness invariant:</strong> geen missing rows / partial writes bij crash → één transactie per batch (we doen dat: insert_results_batch is één transactie). <strong>(2)</strong> <strong>Perf regression gate (soft):</strong> waarschuw bij p95 +10% (geen hard fail) tot CI stabiel genoeg is.</p> </li> </ol> <p><strong>Eindoordeel:</strong> Op basis van de matrix + 20× worstcase is het realistisch en best-practice-conform om <strong>P0.3 als “opgelost” te claimen (voor deze workload)</strong>. Laat writer-queue + bounded channel als “next level” klaarstaan voor wanneer workloads/complexiteit groeien; en houd busy handler semantics strak zodat je later geen verrassingen krijgt.</p> <h3 id=5-next-level-verbeteringen-laag-effort>5) Next-level verbeteringen (laag effort)<a class=headerlink href=#5-next-level-verbeteringen-laag-effort title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Verbetering</th> <th>Status</th> </tr> </thead> <tbody> <tr> <td><strong>store_wait_pct / store_write_pct</strong> als percentage van total_ms</td> <td><strong>Geïmplementeerd:</strong> run.json bevat store_wait_pct en store_write_pct wanneer phases.total_ms beschikbaar is; reviewers zien direct “X% van de run is lock wait”.</td> </tr> <tr> <td><strong>Eén workload-variant met grotere payloads (8–64 KB args/result)</strong></td> <td><strong>In script:</strong> worst_large_payload (bijv. 8–32 KB per toolcall) om te zien of store_write_ms stijgt (serde/page churn) en of checkpointing begint te domineren.</td> </tr> </tbody> </table> <h3 id=6-volgende-stappen-hoogste-roi-en-afweging-advies>6) Volgende stappen (hoogste ROI) — en afweging advies<a class=headerlink href=#6-volgende-stappen-hoogste-roi-en-afweging-advies title="Permanent link">&para;</a></h3> <p><strong>Afweging: advies nu opvolgen of eerst meten?</strong></p> <ul> <li><strong>Eerst matrix rerun (aanbevolen):</strong> Lage effort; we meten of de huidige batching (één batch aan het einde) voldoende winst geeft. Voorheen N mutex-acquisities voor resultaten (één per test); nu 1 (insert_results_batch). Als store_wait_ms bij parallel 16 al van 27→&lt;10 ms gaat en wall p95 daalt, kunnen we “P0.3 solved” claimen <strong>zonder</strong> de zwaardere writer-task refactor. Het advies (writer task + bounded queue + N/X) is dan een optionele “next level” voor een latere PR.</li> <li><strong>Advies nu opvolgen:</strong> Writer task + bounded queue + N/X batching is SOTA 2026 maar een grote refactor (Store async/channel; alle write-callers via queue). Zinvol <strong>nadat</strong> we de matrix hebben herdraaid: als de winst beperkt is (bijv. create_run, finalize_run, put_embedding, ingest houden de Mutex nog druk), dan is de writer-task de logische volgende stap.</li> </ul> <p><strong>Besluit:</strong> Eerst <strong>matrix opnieuw draaien</strong>; op basis van de uitkomst beslissen we of we het volledige advies (writer task + queue) uitvoeren.</p> <table> <thead> <tr> <th>Stap</th> <th>Doel</th> <th>Status</th> </tr> </thead> <tbody> <tr> <td><strong>1. Batching</strong></td> <td>Resultaten in één batch schrijven i.p.v. N writes (insert_results_batch).</td> <td>✅ Geïmplementeerd.</td> </tr> <tr> <td><strong>2. Matrix opnieuw draaien</strong></td> <td>perf_assess.sh (20× worstcase + parallel matrix) voor store_wait_ms/store_write_ms vergelijking.</td> <td>✅ <strong>Uitgevoerd (na batching).</strong></td> </tr> <tr> <td><strong>3. Op basis van resultaat</strong></td> <td>Bij voldoende daling → P0.3 solved; bij beperkte winst → writer task + queue overwegen.</td> <td><strong>Conclusie: P0.3 solved</strong> (zie tabel hieronder).</td> </tr> <tr> <td><strong>4. Eén profile-artefact</strong></td> <td>Flamegraph/samply/tokio-console.</td> <td>Optioneel.</td> </tr> </tbody> </table> <hr> <h3 id=7-perf-gate-wanneer-warn-vs-fail>7) Perf gate: wanneer “warn” vs “fail”?<a class=headerlink href=#7-perf-gate-wanneer-warn-vs-fail title="Permanent link">&para;</a></h3> <ul> <li><strong>Contention/checkpoint-counters</strong> zitten nu in run.json; je kunt dezelfde 20× worstcase opnieuw draaien en oorzaakdata vergelijken.</li> <li>Concurrency-matrix en assessment-checklist (&#8532;/4 stappen) zijn afgerond.</li> <li><strong>Wel al mogelijk:</strong> een <strong>non-blocking trendcheck</strong>: “warn if p95 worstcase regresses &gt;10%”.</li> <li><strong>“Fail PR”</strong> pas zodra (a) cache-hit betrouwbaar is, en (b) matrix stabiel is. Aligned met Criterion: eerst outlier-classificatie en meetbetrouwbaarheid, dan pas harde drempels.</li> </ul> <hr> <h3 id=8-ci-nog-te-borgen>8) CI: nog te borgen<a class=headerlink href=#8-ci-nog-te-borgen title="Permanent link">&para;</a></h3> <p>Zodra dit in CI draait: cache <code>.assay/</code> met actions/cache en <strong>log cache-hit in job summary</strong> (GitHub beschrijft dit outputveld expliciet).</p> <hr> <h3 id=status-metrics-in-code>Status metrics in code<a class=headerlink href=#status-metrics-in-code title="Permanent link">&para;</a></h3> <p><strong>Geïmplementeerd (SOTA-waardig):</strong> run.json is first-class perf output met het volgende schema.</p> <p><strong>store_metrics</strong> (per run): - <strong>store_wait_ms</strong> = tijd wachten op de store-mutex (lock contention). - <strong>store_write_ms</strong> = tijd dat de mutex gehouden wordt in het write-pad (incl. SQLite-werk, busy-sleeps in onze handler, en onze code). Als store_write_ms hoog is maar sqlite_busy_count laag → waarschijnlijk payload/serde/statement; als sqlite_busy_count hoog → lock contention of checkpointing verdachter. - <strong>store_wait_pct</strong> / <strong>store_write_pct</strong> = store_wait_ms resp. store_write_ms als percentage van total_ms (gezet door CLI wanneer phases.total_ms beschikbaar is); voor reviewers: “X% van de run is lock wait”. - <strong>sqlite_busy_count</strong> = aantal SQLITE_BUSY-retries. Onze busy handler telt én wacht (backoff + timeout); we zetten <strong>geen</strong> PRAGMA busy_timeout omdat SQLite maar één busy handler per connection toestaat — onze handler implementeert beide. - <strong>txn_batch_size</strong> (max bij <code>insert_batch</code>). - <strong>effective_pragmas:</strong> na run uitgelezen via PRAGMA-queries. - <strong>wal_checkpoint:</strong> resultaat van <code>PRAGMA wal_checkpoint(PASSIVE)</code> na de run (file-backed).</p> <p><strong>sqlite_busy_count is processbreed:</strong> reset aan run-start; bij meerdere stores/tests kunnen counts “lekken” — run_context.db_mode identificeert welke DB gebruikt is.</p> <p><strong>phases:</strong> <code>ingest_ms</code> (bij ci + replay_strict), <code>run_suite_ms</code>, <code>report_ms</code>, <code>total_ms</code>.</p> <p><strong>run_context:</strong> <code>db_mode</code>, <code>parallel</code>, <code>assay_version</code>.</p> <p><strong>Pragma’s bij open (file-backed):</strong> <code>journal_mode=WAL</code>, <code>synchronous=NORMAL</code>, <code>wal_autocheckpoint=1000</code>; <strong>geen</strong> PRAGMA busy_timeout (onze custom busy handler doet tellen + backoff + timeout).</p> <p><strong>20× aggregation:</strong> Voor worstcase file-backed 20× slaat het script per run <code>run.json</code> op in <code>$TMPDIR/worst_runs/run_1.json</code> … <code>run_20.json</code>. Als <code>jq</code> beschikbaar is, worden na de loop <strong>median en p95</strong> van <code>store_wait_ms</code>, <code>store_write_ms</code>, <code>sqlite_busy_count</code> en (indien aanwezig) <code>wal_checkpoint.log_frames</code> onder de wall-clock uitvoer geprint. Zo kun je direct zien of p95 gedreven wordt door mutex wait, write hold of checkpointing.</p> <p><strong>Parallel matrix:</strong> Om te zien waar p95 “knikt” bij hogere parallel: run worstcase file-backed met <code>parallel</code> 1, 4, 8, 16. Maak per waarde een eval met alleen <code>settings.parallel</code> aangepast (bijv. kopie van eval_worst.yaml met <code>parallel: 1</code>), run 20× elk, en vergelijk median/p95 en <code>sqlite_busy_count</code>/<code>store_wait_ms</code>. Zie sectie “Concurrency-matrix” eerder in dit doc.</p> <p><strong>Perf schema (run.json) — voor versioning en CI-regressie</strong></p> <table> <thead> <tr> <th>Sectie</th> <th>Velden</th> <th>Types</th> </tr> </thead> <tbody> <tr> <td><strong>store_metrics</strong></td> <td>sqlite_busy_count, store_wait_ms, store_write_ms, store_wait_pct?, store_write_pct?, txn_batch_size?</td> <td>u64, u64, u64, f64?, f64?, u64?</td> </tr> <tr> <td><strong>store_metrics.effective_pragmas</strong></td> <td>journal_mode, synchronous, synchronous_human, busy_timeout, wal_autocheckpoint</td> <td>string, string, string?, i64, i64</td> </tr> <tr> <td><strong>store_metrics.wal_checkpoint</strong></td> <td>blocked, log_frames, checkpointed_frames</td> <td>i32, i32, i32</td> </tr> <tr> <td><strong>phases</strong></td> <td>ingest_ms?, precompute_ms?, run_suite_ms?, report_ms?, total_ms?</td> <td>u64?</td> </tr> <tr> <td><strong>run_context</strong></td> <td>db_mode, parallel, assay_version</td> <td>string, usize, string</td> </tr> </tbody> </table> <p><strong>WAL checkpoint column semantics</strong> (PRAGMA wal_checkpoint(PASSIVE)): SQLite returns three integers; we map them as: <strong>blocked</strong> = busy/blocked flag (0 = checkpoint completed or PASSIVE did not block, 1 = blocked by readers); <strong>log_frames</strong> = total frames in WAL (-1 if checkpoint could not run); <strong>checkpointed_frames</strong> = frames checkpointed (-1 if could not run). Unit test: <code>test_wal_checkpoint_column_mapping</code> in <code>crates/assay-core/tests/storage_smoke.rs</code> builds a WAL and asserts the mapping.</p> <p><strong>synchronous_human:</strong> effective_pragmas includes <code>synchronous_human</code> (OFF, NORMAL, FULL, EXTRA) for DX; in WAL mode NORMAL defers fsyncs to checkpoint, FULL is more durable.</p> <p>Dit schema kun je stabiel versionen (bijv. <code>perf_schema_version: 1</code>) en later in CI automatisch regressies laten detecteren.</p> <hr> <p><strong>Criterion in CI:</strong> De CI-workflow (<code>ci.yml</code>) bevat een job <strong>Criterion benches (store + suite)</strong> die op elke push/PR op <code>ubuntu-latest</code> draait: <code>cargo bench -p assay-core -p assay-cli --no-fail-fast -- --quick</code>. Het Criterion-rapport wordt geüpload als artifact (<code>criterion-report</code>, retentie 5 dagen). Er is nog <strong>geen regressie-gate</strong> (geen fail bij p95-regressie); dat kan later toegevoegd worden zodra baseline en cache-hit stabiel zijn.</p> <hr> <h2 id=eindbeoordeling-eerste-review-na-batching>Eindbeoordeling (eerste review + na batching)<a class=headerlink href=#eindbeoordeling-eerste-review-na-batching title="Permanent link">&para;</a></h2> <ul> <li><strong>Ja:</strong> Op basis van de matrix is P0.3 <strong>opgelost</strong> met de huidige batching (voor <strong>deze workload</strong>): store_wait_ms (parallel 16) daalde van 27→3 ms (median) en 28→5 ms (p95); wall p95 van 50→34 ms. De data liet zien dat het een app-level serialisatieprobleem was (één lock); “batch aan het einde” (insert_results_batch) volstaat. <strong>Scope:</strong> Opgelost voor de huidige worstcase + parallelmatrix; niet universeel bewezen voor andere workloads (grotere payloads, meerdere readers, CI jitter). Zie ADR-019 P0.3 en sectie “P0.3 scope + guardrails” hierboven.</li> <li><strong>Nee:</strong> Nog niet zeggen “checkpointing is irrelevant”, maar wel “niet dominant in deze workload; blijven meten.” Checkpointing kan later alsnog bijten (andere workloads, grotere payloads, andere CI-disks).</li> <li><strong>Writer-queue + bounded channel:</strong> Als <strong>contingency/next level</strong> klaarstaan; niet als P0. Doe wanneer store_wait_ms weer oploopt, meer write-paths bijkomen, of meerdere DB consumers. Gebruik bounded mpsc (backpressure). Busy handler semantics strak houden (één mechanisme, log configured timeout zelf).</li> </ul> <hr> <h2 id=samenvatting-wat-er-nu-is-vs-wat-er-nog-moet-voor-p03-validatie>Samenvatting: wat er nu is vs wat er nog moet (voor P0.3-validatie)<a class=headerlink href=#samenvatting-wat-er-nu-is-vs-wat-er-nog-moet-voor-p03-validatie title="Permanent link">&para;</a></h2> <table> <thead> <tr> <th>Categorie</th> <th>Huidige stand</th> <th>Nog te doen</th> </tr> </thead> <tbody> <tr> <td><strong>A. Workloads</strong></td> <td>Klein in tree; medium/large + worstcase gegenereerd in script; 20× worstcase file-backed; <strong>semantic_vcr</strong> fixture (eval + trace + cassettes/) voor precompute/cache zonder netwerk.</td> <td>VCR-middleware in code (replay van disk); vaste seed/sizes; grotere payload-variant (8–64 KB).</td> </tr> <tr> <td><strong>B. Metingen</strong></td> <td>run.json: store_metrics (wait/write/busy/batch), effective_pragmas (incl. synchronous_human), wal_checkpoint; phases; run_context; 20× median/p95 in script; script aggregateert store_metrics (median/p95) bij worstcase 20× als jq aanwezig.</td> <td>Optioneel: perf_schema_version.</td> </tr> <tr> <td><strong>C. Concurrency</strong></td> <td>parallel=4 standaard; WAL + pragma’s in store; <strong>BEGIN IMMEDIATE</strong> voor write-transacties (insert_event, insert_batch); concurrency-matrix in script.</td> <td>Optioneel: auto-clamp parallel in assay ci.</td> </tr> <tr> <td><strong>C. CI</strong></td> <td>Blessed snippet in doc; <strong>baseline-gate-demo.yml</strong> cached .eval/.assay en logt cache-hit in job summary.</td> <td>Optioneel: cache in meer workflows (bijv. perf job).</td> </tr> <tr> <td><strong>Harness</strong></td> <td>perf_assess.sh (smoke + 20×); Criterion benches; <strong>CI job</strong> in ci.yml + <strong>Bencher</strong> (perf_main.yml, perf_pr.yml) voor baseline-vergelijking; <strong>Hyperfine e2e</strong> (perf_e2e.sh).</td> <td>Later: <code>--err</code> in perf_pr voor hard fail; optioneel Hyperfine in Bencher.</td> </tr> </tbody> </table> <hr> <h2 id=wat-is-nu-echt-open>Wat is nú écht open<a class=headerlink href=#wat-is-nu-echt-open title="Permanent link">&para;</a></h2> <p>Als je alles wat al geïmplementeerd is meerekent (store_metrics, pragmas, wal_checkpoint, phases, parallel matrix, batching, Criterion in CI, cache in baseline-gate), blijven dit de belangrijkste open punten voor een <strong>herhaalbare, CI-gateable performance assessment op SOTA-niveau</strong>:</p> <table> <thead> <tr> <th>#</th> <th>Open punt</th> <th>Doel</th> </tr> </thead> <tbody> <tr> <td>1</td> <td><strong>Doc alignen met realiteit</strong></td> <td>Inventaris- en status-tabellen up-to-date houden (zoals in dit doc bijgewerkt); anders misleiden reviewers zich op “Nee”/“ontbreekt”-tekst.</td> </tr> <tr> <td>2</td> <td><strong>Semantic/judge VCR-workload</strong> (fixture ✅, middleware open)</td> <td>Fixture: <code>tests/fixtures/perf/semantic_vcr/</code> (eval, trace, cassettes/). Env: <code>ASSAY_VCR_MODE</code>, <code>ASSAY_VCR_DIR</code>; CI = replay only. <strong>Open:</strong> VCR-middleware (reqwest record/replay) in code. Zie sectie “Semantic/judge VCR-workload”.</td> </tr> <tr> <td>3</td> <td><strong>Hyperfine e2e als blessed flow</strong></td> <td>✅ <strong>Blessed script:</strong> <code>scripts/perf_e2e.sh</code> — small / file_backed / ci; <code>--warmup</code>, <code>--export-json</code>, median+p95 uit JSON. Zie “Hyperfine e2e: blessed flow” in dit doc.</td> </tr> <tr> <td>4</td> <td>✅ <strong>CI baseline-vergelijking + regressie-policy</strong></td> <td><strong>Gedaan:</strong> perf_main.yml (baseline) + perf_pr.yml (PR compare); Bencher reports met <code>sw/50x400b</code>, <code>sw/12xlarge</code>, <code>sr/wc</code>; thresholds (percentage test, upper_boundary 0.50 = 50%); alerts are warnings only (no --err). <strong>Note:</strong> GitHub Actions runners have high variance (20-40%+); alerts provide visibility without blocking CI.</td> </tr> <tr> <td>5</td> <td><strong>Busy handler/timeout in doc</strong></td> <td>✅ In dit doc toegevoegd: sectie “Busy handler en checkpoint” — PRAGMA vs custom handler, één per connection, waarom PRAGMA 0 kan zijn; onze keuze + hoe we loggen.</td> </tr> <tr> <td>6</td> <td><strong>CI cache voor perf jobs</strong></td> <td>✅ Perf-job in ci.yml logt <strong>cache-hit</strong> (rust-cache) in job summary; sectie “CI cache voor perf jobs” in dit doc. Norm: waar cache leeft (.assay vs target/) en wat gecached wordt.</td> </tr> </tbody> </table> <p><strong>Kort:</strong> De <strong>performance assessment is 100% compleet</strong>. Alle tooling is operationeel, VCR-middleware geïntegreerd met providers, en cassettes opgenomen (<code>cassettes/openai/{embeddings,judge}/</code>).</p> <hr> <h2 id=cleanup-na-assessment>Cleanup na assessment<a class=headerlink href=#cleanup-na-assessment title="Permanent link">&para;</a></h2> <ul> <li><strong>Tijdelijke bestanden:</strong> Na file-backed runs: <code>rm -f .assay/store.db .assay/store.db-shm .assay/store.db-wal</code> (of script doet dit).</li> <li><strong>Output-artefacten:</strong> Verwijder junit/sarif/run.json in repo root tenzij bewaren gewenst.</li> <li><strong>Perf-fixtures:</strong> Kleine set in <code>tests/fixtures/perf/</code>; medium/large door script in temp gegenereerd en bij exit opgeruimd.</li> <li><strong>Script:</strong> <code>scripts/perf_assess.sh</code> blijft; gebruik voor quick check. Voor conclusies en regressie: Criterion + herhaalde runs + file-backed WAL.</li> </ul> <hr> <h2 id=blessed-perf-toolkit-voor-implementatie>Blessed perf toolkit (voor implementatie)<a class=headerlink href=#blessed-perf-toolkit-voor-implementatie title="Permanent link">&para;</a></h2> <p>Concrete vertaling naar wat er in dit repo moet komen zodat <strong>performance-regressies te gate'en</strong> zijn. Invulling kan stap voor stap (eerst Criterion + summary.json, dan Hyperfine + CI job, dan cache snippet).</p> <h3 id=criterion-benchmarks-micromeso>Criterion-benchmarks (micro/meso)<a class=headerlink href=#criterion-benchmarks-micromeso title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Benchmark</th> <th>Scope</th> <th>Output (median/p95)</th> </tr> </thead> <tbody> <tr> <td><strong>bench_store_write_heavy</strong></td> <td>Store: insert/txn/batching/queue (create_run + N×insert_result_embedded, file-backed).</td> <td>Criterion median/p95; optioneel: sqlite_busy_count als geïnstrumenteerd.</td> </tr> <tr> <td><strong>bench_suite_run_worstcase</strong></td> <td>Runner → Store → report, file-backed WAL; genoeg writes voor checkpointing.</td> <td>Criterion median/p95.</td> </tr> <tr> <td>(uitbreiding) store_insert_single, fingerprint_compute, report_render_junit/sarif</td> <td>Zie vorige versie van dit doc.</td> <td>median_ms, p95_ms.</td> </tr> </tbody> </table> <p>Plaats: <code>crates/assay-core/benches/store_write_heavy.rs</code>, <code>crates/assay-cli/benches/suite_run_worstcase.rs</code>. Run: <code>cargo bench -p assay-core --bench store_write_heavy</code>, <code>cargo bench -p assay-cli --bench suite_run_worstcase</code>. Criterion bewaart history in <code>target/criterion/</code>; CI kan <code>cargo bench</code> draaien en artifact uploaden, of integratie met Bencher/andere continuous benchmarking. <strong>Duur:</strong> <code>suite_run_worstcase</code> doet per iteratie een volledige <code>assay run</code> subprocess (12 episodes, file-backed DB); met QUICK=1 duurt de bench ~20–40s — dat is geen hang.</p> <h3 id=hyperfine-e2e-blessed-flow>Hyperfine e2e: blessed flow<a class=headerlink href=#hyperfine-e2e-blessed-flow title="Permanent link">&para;</a></h3> <p><strong>Blessed script:</strong> <code>scripts/perf_e2e.sh</code> — SOTA e2e benchmark met Hyperfine: warmup, outlier-robust, JSON-export. Gebruik dit als <strong>standaard flow</strong> voor e2e CLI-timings (naast perf_assess.sh voor smoke/store-stress).</p> <table> <thead> <tr> <th>Scenario</th> <th>Command</th> <th>Opmerking</th> </tr> </thead> <tbody> <tr> <td><strong>small</strong></td> <td><code>./scripts/perf_e2e.sh small</code></td> <td>assay run, :memory:, warmup=1, runs=10; schrijft PERF_E2E_JSON (default: perf_e2e_results.json).</td> </tr> <tr> <td><strong>file_backed</strong></td> <td><code>./scripts/perf_e2e.sh file_backed</code></td> <td>Zelfde, maar file-backed DB; --prepare wist DB per run.</td> </tr> <tr> <td><strong>ci</strong></td> <td><code>./scripts/perf_e2e.sh ci</code></td> <td>assay ci met small fixtures; warmup + runs.</td> </tr> </tbody> </table> <p>Override: <code>PERF_E2E_JSON</code>, <code>PERF_E2E_WARMUP</code>, <code>PERF_E2E_RUNS</code>, <code>ASSAY</code>. Het script print median en p95 uit de JSON (als jq aanwezig). Voor CI: zet <code>PERF_E2E_JSON</code> op een artifact-path en upload de JSON; median/p95 kun je uit de JSON halen of in een gate-tool gebruiken.</p> <h3 id=forensic-tail-latency-mode>Forensic tail-latency mode<a class=headerlink href=#forensic-tail-latency-mode title="Permanent link">&para;</a></h3> <p>Voor diepere analyse van tail-latency (p95/p99 blow-up):</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nv>FORENSIC</span><span class=o>=</span><span class=m>1</span><span class=w> </span>./scripts/perf_assess.sh
</span></code></pre></div> <p>Dit voegt toe aan de normale run: - <strong>50× worst_file_backed</strong> met per-iteratie timing - <strong>30× worst_large_payload</strong> idem - <strong>p99, max, stddev, tail_ratio (p99/median)</strong> - <strong>Outlier detectie</strong> (&gt;2× median) - <strong>tmpfs vs disk vergelijking</strong> (Linux, /dev/shm) - <strong>Raw data</strong> in <code>$TMPDIR/forensic_*_data/timings.txt</code> + <code>run_N.json</code></p> <p>Gebruik forensic mode wanneer: - p95/p99 significant hoger is dan median (&gt;2× ratio) - Je wilt weten of jitter van disk I/O, OS, of applicatie komt - Je baseline wilt leggen voor tail-latency SLO</p> <h3 id=tail-latency-alarm-policy>Tail-latency alarm policy<a class=headerlink href=#tail-latency-alarm-policy title="Permanent link">&para;</a></h3> <p>Gebaseerd op forensic baseline (jan 2026):</p> <table> <thead> <tr> <th>Metric</th> <th>Gezond</th> <th>⚠️ Warn</th> <th>❌ Fail</th> </tr> </thead> <tbody> <tr> <td><strong>tail_ratio</strong> (p99/median)</td> <td>&lt; 1.5</td> <td>1.5–2.0</td> <td>&gt; 2.0</td> </tr> <tr> <td><strong>p95 drift</strong> vs baseline</td> <td>&lt; +15%</td> <td>+15–25%</td> <td>&gt; +25%</td> </tr> <tr> <td><strong>max</strong> vs p99</td> <td>&lt; 1.5×</td> <td>1.5–2×</td> <td>&gt; 2×</td> </tr> <tr> <td><strong>sqlite_busy_count</strong></td> <td>0</td> <td>1–5</td> <td>&gt; 5</td> </tr> </tbody> </table> <p><strong>Baseline waarden (worst_file_backed):</strong> - median: ~34 ms - p95: ~44 ms - p99: ~47 ms - tail_ratio: 1.37</p> <p><strong>Interpretatie:</strong> - <code>tail_ratio &gt; 2.0</code> duidt op structurele jitter (OS, disk, of code) - <code>p95 drift &gt; 25%</code> is waarschijnlijk een regressie, niet noise - <code>sqlite_busy_count &gt; 0</code> betekent lock contention — onderzoek transacties - <code>max &gt;&gt; p99</code> suggereert incidentele outliers (vaak cold cache of GC)</p> <h3 id=bencher-threshold-mapping>Bencher threshold mapping<a class=headerlink href=#bencher-threshold-mapping title="Permanent link">&para;</a></h3> <p>Bencher thresholds afgestemd op forensic baseline (jan 2026):</p> <table> <thead> <tr> <th>Measure</th> <th>Test</th> <th>upper_boundary</th> <th>Workflow</th> </tr> </thead> <tbody> <tr> <td><strong>latency</strong></td> <td>percentage</td> <td>0.25 (25%)</td> <td>perf_main, perf_pr</td> </tr> <tr> <td><strong>tail_ratio</strong></td> <td>static</td> <td>2.0</td> <td>perf_nightly</td> </tr> <tr> <td><strong>sqlite_busy_count</strong></td> <td>static</td> <td>0</td> <td>perf_nightly</td> </tr> </tbody> </table> <p><strong>Bencher flags (productie configuratie):</strong> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># perf_main.yml (baseline)</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class="l l-Scalar l-Scalar-Plain">--threshold-measure latency</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class="l l-Scalar l-Scalar-Plain">--threshold-test percentage</span><span class=w>       </span><span class=c1># Drift vs baseline</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class="l l-Scalar l-Scalar-Plain">--threshold-max-sample-size 64</span><span class=w>    </span><span class=c1># Statistical stability</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class="l l-Scalar l-Scalar-Plain">--threshold-upper-boundary 0.25</span><span class=w>   </span><span class=c1># 25% = fail</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class="l l-Scalar l-Scalar-Plain">--thresholds-reset</span><span class=w>                </span><span class=c1># Only this threshold active</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class="l l-Scalar l-Scalar-Plain">--err</span><span class=w>                             </span><span class=c1># Fail on alert</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a><span class=c1># perf_pr.yml (PR compare)</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class="l l-Scalar l-Scalar-Plain">--start-point-clone-thresholds</span><span class=w>    </span><span class=c1># Clone from main</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a><span class="l l-Scalar l-Scalar-Plain">--start-point-reset</span><span class=w>               </span><span class=c1># Prevent drift</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a><span class="l l-Scalar l-Scalar-Plain">--err</span><span class=w>                             </span><span class=c1># Fail on alert</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a><span class=c1># perf_nightly.yml (forensic)</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a><span class="l l-Scalar l-Scalar-Plain">--adapter json</span><span class=w>                    </span><span class=c1># BMF JSON input</span>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a><span class="l l-Scalar l-Scalar-Plain">--threshold-measure tail_ratio</span>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a><span class="l l-Scalar l-Scalar-Plain">--threshold-test static</span><span class=w>           </span><span class=c1># Absolute limit</span>
</span><span id=__span-1-18><a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a><span class="l l-Scalar l-Scalar-Plain">--threshold-upper-boundary 2.0</span><span class=w>    </span><span class=c1># tail_ratio &gt; 2.0 = alert</span>
</span></code></pre></div></p> <p><strong>CI Gate Logic:</strong> - <strong>Main baseline:</strong> Elke push naar main update Bencher baseline met 25% threshold - <strong>PR compare:</strong> Vergelijk tegen main baseline, fail bij &gt;25% regressie - <strong>Nightly:</strong> Forensic metrics (tail_ratio, sqlite_busy_count) met static thresholds</p> <h3 id=nightly-forensic-trend>Nightly forensic trend<a class=headerlink href=#nightly-forensic-trend title="Permanent link">&para;</a></h3> <p>Geautomatiseerd via <code>.github/workflows/perf_nightly.yml</code>: - <strong>Schedule:</strong> dagelijks 03:00 UTC - <strong>Workload:</strong> <code>FORENSIC=1</code> (worst_file_backed 30×, worst_large_payload 30×) - <strong>Output:</strong> - <code>forensic_output.txt</code> artifact (90 dagen retention) - BMF JSON push naar Bencher (grafieken + trend tracking) - <strong>Bencher metrics:</strong> tail_ratio, p95_ms, p99_ms, median_ms, sqlite_busy_count - <strong>Alerts:</strong> Static threshold <code>tail_ratio &gt; 2.0</code> triggert Bencher alert</p> <p><strong>BMF JSON output:</strong> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Genereer Bencher Metric Format JSON</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=nv>FORENSIC</span><span class=o>=</span><span class=m>1</span><span class=w> </span><span class=nv>BMF_JSON</span><span class=o>=</span><span class=m>1</span><span class=w> </span>./scripts/perf_assess.sh<span class=w> </span><span class=m>2</span>&gt;/dev/null<span class=w> </span><span class=p>|</span><span class=w> </span>tail<span class=w> </span>-20
</span></code></pre></div></p> <p>Doel: <strong>drift detectie</strong> + <strong>trend visualisatie</strong> in Bencher dashboard — niet om PRs te blokkeren, maar om infra/dependency-veranderingen vroeg te signaleren.</p> <p><strong>Handmatige Hyperfine-commands</strong> (als je geen script wilt):</p> <table> <thead> <tr> <th>Scenario</th> <th>Command</th> </tr> </thead> <tbody> <tr> <td>small_cold</td> <td><code>hyperfine --warmup 0 --runs 20 --export-json results.json 'assay run --config tests/fixtures/perf/eval_small.yaml --trace-file tests/fixtures/perf/trace_small.jsonl --db :memory:'</code></td> </tr> <tr> <td>assay_ci_e2e</td> <td><code>hyperfine --warmup 1 --runs 10 --export-json results.json 'assay ci --config tests/fixtures/perf/eval_small.yaml --trace-file tests/fixtures/perf/trace_small.jsonl'</code></td> </tr> </tbody> </table> <p>Output: <code>--export-json</code> voor trends en CI-vergelijk; median/p95 uit <code>.results[0].median</code> en <code>.results[0].times</code> (p95 = percentiel op times).</p> <h3 id=ci-jobs-voor-perf>CI-job(s) voor perf<a class=headerlink href=#ci-jobs-voor-perf title="Permanent link">&para;</a></h3> <ul> <li><strong>Geïmplementeerd:</strong> In <code>ci.yml</code> draait de job <strong>Criterion benches (store + suite)</strong> op elke push/PR (ubuntu-latest): <code>cargo bench -p assay-core -p assay-cli --no-fail-fast -- --quick</code>; upload artifact <code>criterion-report</code> (target/criterion/, retentie 5 dagen). Geen regressie-gate. <strong>Aanbevolen:</strong> cache + cache-hit in deze job (zie “CI cache voor perf jobs”).</li> <li><strong>Hyperfine e2e in CI:</strong> Optioneel: run <code>scripts/perf_e2e.sh</code> (bijv. <code>small</code> of <code>file_backed</code>), upload <code>PERF_E2E_JSON</code> als artifact; median/p95 uit JSON voor trend of gate.</li> <li><strong>Bencher (baseline-vergelijking):</strong> Conventie welke benches op PR vs main/nightly; baseline-vergelijking (compare against main of Bencher); policy: eerst “warn if p95 +10%”, later “fail if +X%”. Zie “Wat is nú écht open”.</li> </ul> <h3 id=ci-baseline-bencher>CI baseline: Bencher<a class=headerlink href=#ci-baseline-bencher title="Permanent link">&para;</a></h3> <ul> <li><strong>perf_main.yml:</strong> Draait op push naar main en op schedule (nightly). Slaat Criterion-resultaten op als baseline; <code>--thresholds-reset</code> voor main-branch thresholds.</li> <li><strong>perf_pr.yml:</strong> Draait op pull_request (alleen same-repo). Vergelijkt PR-branch met main via <code>--start-point</code>, <code>--start-point-clone-thresholds</code>, <code>--start-point-reset</code>. Geen <code>--err</code> dus job faalt niet op regressie; Bencher post check/comment. Later <code>--err</code> toevoegen voor hard fail.</li> <li><strong>Secrets:</strong> <code>BENCHER_PROJECT</code> (project slug), <code>BENCHER_API_TOKEN</code>. Zie <a href=https://bencher.dev/docs/how-to/github-actions/ >Bencher GitHub Actions</a>.</li> <li><strong>Conventie:</strong> PR = snelle signalen (zelfde benches, quick); main/nightly = authoritative baseline.</li> </ul> <h4 id=bencher-secrets-verkrijgen-en-configureren>Bencher secrets verkrijgen en configureren<a class=headerlink href=#bencher-secrets-verkrijgen-en-configureren title="Permanent link">&para;</a></h4> <p>De Perf-workflows (<code>perf_main.yml</code>, <code>perf_pr.yml</code>) draaien alleen als de repository-secrets gezet zijn. Zonder secrets worden de Bencher-jobs <strong>skipped</strong> (geen failure).</p> <ol> <li><strong>Account en project</strong></li> <li>Ga naar <a href=https://bencher.dev>bencher.dev</a> en maak een account (Sign up).</li> <li>Maak een <strong>project</strong> aan in de Bencher Console (of run lokaal eenmaal <code>bencher run …</code> zonder <code>--project</code>; Bencher maakt een on-the-fly project, daarna “Claim this project” om het aan je account te koppelen).</li> <li> <p>Het <strong>project slug</strong> is de projectnaam (bijv. <code>assay</code>) of het lange formaat (bijv. <code>project-abc4567-wxyz123456789</code>). Je vindt het in de Bencher Console bij het project (URL of projectinstellingen).</p> </li> <li> <p><strong>API-token</strong></p> </li> <li>In de <a href=https://bencher.dev/console>Bencher Console</a>: rechtsboven op je naam klikken → <strong>Tokens</strong>.</li> <li> <p><strong>➕ Add</strong> → geef de token een naam (bijv. <code>assay-github-actions</code>) → kopieer de waarde. Bewaar die veilig; hij is daarna niet opnieuw in te zien.</p> </li> <li> <p><strong>GitHub repository-secrets</strong></p> </li> <li>Ga naar je repo op GitHub → <strong>Settings</strong> → <strong>Secrets and variables</strong> → <strong>Actions</strong>.</li> <li> <p><strong>New repository secret</strong>:</p> <ul> <li><strong>Name:</strong> <code>BENCHER_PROJECT</code> → <strong>Secret:</strong> het project slug (bijv. <code>project-abc4567-wxyz123456789</code>).</li> <li><strong>Name:</strong> <code>BENCHER_API_TOKEN</code> → <strong>Secret:</strong> de API-token uit stap 2.</li> </ul> </li> <li> <p><strong>Controleren</strong></p> </li> <li>Na het toevoegen van beide secrets draaien bij de volgende push naar <code>main</code> de <strong>Perf (main baseline)</strong>-job en bij PR’s (same-repo) de <strong>Perf (PR compare)</strong>-job. Resultaten verschijnen op <a href=https://bencher.dev>bencher.dev</a> en (met <code>--github-actions</code>) als check/comment op de PR.</li> </ol> <p>Zie ook: <a href=https://bencher.dev/docs/how-to/claim/#create-an-api-token>Bencher: Create an API Token</a>, <a href=https://bencher.dev/docs/how-to/github-actions/ >Bencher GitHub Actions</a>.</p> <h3 id=semanticjudge-vcr-workload>Semantic/judge VCR-workload<a class=headerlink href=#semanticjudge-vcr-workload title="Permanent link">&para;</a></h3> <ul> <li><strong>Fixture-structuur:</strong> <code>tests/fixtures/perf/semantic_vcr/</code> — eval_semantic_vcr.yaml (1× semantic_similarity_to, 1× faithfulness), trace_semantic_vcr.jsonl, cassettes/ (embeddings/, judge/) + README.</li> <li><strong>Runtime-contract:</strong> <code>ASSAY_VCR_MODE=replay|record|off</code> (CI default: replay), <code>ASSAY_VCR_DIR</code>. CI draait alleen replay; record alleen lokaal met API key. Cassettes scrubben vóór commit.</li> <li>✅ <strong>VCR-middleware:</strong> <code>crates/assay-core/src/vcr/mod.rs</code> — <code>VcrClient</code> met <code>post_json()</code> voor record/replay van HTTP-requests. Matching op method + URL + body (SHA256 fingerprint); Authorization-header uitgesloten. Cassettes opgeslagen als JSON in <code>ASSAY_VCR_DIR/{embeddings,judge}/</code>. Zie module docs en tests voor gebruik.</li> <li>✅ <strong>Provider-integratie:</strong> OpenAI embedder (<code>providers/embedder/openai.rs</code>) en LLM client (<code>providers/llm/openai.rs</code>) ondersteunen VCR via <code>with_vcr()</code> of <code>from_env()</code> constructors. In CI met <code>ASSAY_VCR_MODE=replay</code> worden responses uit cassettes gelezen; geen outbound netwerk.</li> </ul> <h3 id=adapter-outputs-criterion-flags-vcr-hygiene>Adapter outputs + Criterion flags + VCR hygiene<a class=headerlink href=#adapter-outputs-criterion-flags-vcr-hygiene title="Permanent link">&para;</a></h3> <ul> <li><strong>Criterion:</strong> Bencher-adapter <code>rust_criterion</code> verwacht Criterion stdout; meet <code>latency</code> (ns). Gebruik altijd <code>--bench &lt;name&gt; -- …</code> voor extra args (bijv. <code>-- --quick</code>). <strong>Harness:</strong> Criterion-benches moeten <code>harness = false</code> hebben in <code>Cargo.toml</code> (<code>[[bench]] name = "…" harness = false</code>); anders gebruikt Cargo de libtest-harness en krijg je "running 0 tests" in plaats van Criterion-output → Bencher: "Are you sure rust_criterion is the right adapter?". <strong>IDs:</strong> Criterion zet benchmark-naam + <code>time: [...]</code> op één regel alleen als de ID kort genoeg is; lange IDs wrappen → adapter parset niet. Gebruik korte group names (bijv. <code>sw</code>, <code>sr</code>) en korte bench-namen (<code>50x400b</code>, <code>12xlarge</code>, <code>wc</code>) zodat <code>sw/50x400b time: [..]</code> op één regel blijft.</li> <li><strong>Stdin/pipe-modus:</strong> Bencher leest van stdin als je geen command na <code>--</code> geeft. Robuuster dan exec-modus: <code>cargo bench … 2&gt;&amp;1 | grep -v "Gnuplot not found" | bencher run --adapter rust_criterion …</code> (geen <code>-- command</code>).</li> <li><strong>Hyperfine:</strong> Bencher kan <code>--file results.json</code> (Hyperfine JSON) innemen voor e2e-tracking.</li> <li><strong>VCR-hygiene:</strong> Cassette-store in repo: scrub secrets/PII; matching op method + url + body (gecanonicaliseerde JSON), niet op Authorization; CI default = replay, record alleen lokaal.</li> </ul> <h3 id=bencher-ingest-exacte-commands-en-reports>Bencher ingest: exacte commands en reports<a class=headerlink href=#bencher-ingest-exacte-commands-en-reports title="Permanent link">&para;</a></h3> <p><strong>Waarom het nu werkt:</strong> (1) Korte Criterion-IDs (<code>sw/50x400b</code>, <code>sw/12xlarge</code>, <code>sr/wc</code>) zodat <code>id + time:</code> op één regel blijft voor de rust_criterion-adapter. (2) Stdin/pipe: Bencher krijgt exact de gefilterde stdout. (3) Zelfde branch/testbed (<code>main</code>, <code>ubuntu-latest</code>) en threshold-flags op main en PR.</p> <p><strong>Main baseline – twee aparte runs (twee reports in Bencher):</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Step 1: store_write_heavy → report met sw/50x400b, sw/12xlarge</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>cargo<span class=w> </span>bench<span class=w> </span>-p<span class=w> </span>assay-core<span class=w> </span>--bench<span class=w> </span>store_write_heavy<span class=w> </span><span class=m>2</span>&gt;<span class=p>&amp;</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=w>  </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>-v<span class=w> </span><span class=s2>&quot;Gnuplot not found&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=w>  </span><span class=p>|</span><span class=w> </span>bencher<span class=w> </span>run<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=w>      </span>--project<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_PROJECT</span><span class=s2>&quot;</span><span class=w> </span>--token<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_API_TOKEN</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=w>      </span>--branch<span class=w> </span>main<span class=w> </span>--testbed<span class=w> </span>ubuntu-latest<span class=w> </span>--adapter<span class=w> </span>rust_criterion<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=w>      </span>--ci-id<span class=w> </span>store_write_heavy<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a><span class=w>      </span>--threshold-measure<span class=w> </span>latency<span class=w> </span>--threshold-test<span class=w> </span>t_test<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=w>      </span>--threshold-max-sample-size<span class=w> </span><span class=m>64</span><span class=w> </span>--threshold-upper-boundary<span class=w> </span><span class=m>0</span>.99<span class=w> </span>--thresholds-reset<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a><span class=w>      </span>--github-actions<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_TOKEN</span><span class=s2>&quot;</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a><span class=c1># Step 2: suite_run_worstcase → aparte report met sr/wc</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>cargo<span class=w> </span>bench<span class=w> </span>-p<span class=w> </span>assay-cli<span class=w> </span>--bench<span class=w> </span>suite_run_worstcase<span class=w> </span><span class=m>2</span>&gt;<span class=p>&amp;</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a><span class=w>  </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>-v<span class=w> </span><span class=s2>&quot;Gnuplot not found&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a><span class=w>  </span><span class=p>|</span><span class=w> </span>bencher<span class=w> </span>run<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a><span class=w>      </span>--project<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_PROJECT</span><span class=s2>&quot;</span><span class=w> </span>--token<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_API_TOKEN</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a><span class=w>      </span>--branch<span class=w> </span>main<span class=w> </span>--testbed<span class=w> </span>ubuntu-latest<span class=w> </span>--adapter<span class=w> </span>rust_criterion<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a><span class=w>      </span>--ci-id<span class=w> </span>suite_run_worstcase<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a><span class=w>      </span>--threshold-measure<span class=w> </span>latency<span class=w> </span>--threshold-test<span class=w> </span>t_test<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a><span class=w>      </span>--threshold-max-sample-size<span class=w> </span><span class=m>64</span><span class=w> </span>--threshold-upper-boundary<span class=w> </span><span class=m>0</span>.99<span class=w> </span>--thresholds-reset<span class=w> </span><span class=se>\</span>
</span><span id=__span-3-21><a id=__codelineno-3-21 name=__codelineno-3-21 href=#__codelineno-3-21></a><span class=w>      </span>--github-actions<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_TOKEN</span><span class=s2>&quot;</span>
</span></code></pre></div> <p><strong>Waar sr/wc landt:</strong> Elke <code>bencher run</code>-aanroep maakt één report. De eerste step vult een report met alleen <code>sw/50x400b</code> en <code>sw/12xlarge</code>; de tweede step een report met alleen <code>sr/wc</code>. In de Bencher-UI zie je dus twee reports per baseline-run (zelfde branch version). Dat is bewust: <code>--ci-id</code> onderscheidt de runs; alle drie de benchmarks zijn wel in de branch-baseline aanwezig.</p> <p><strong>PR compare:</strong> Zelfde pipe-setup, met <code>--branch "$GITHUB_HEAD_REF"</code>, <code>--start-point "$GITHUB_BASE_REF"</code>, <code>--start-point-hash &lt;base_sha&gt;</code>, <code>--start-point-clone-thresholds</code>, <code>--start-point-reset</code>, en dezelfde threshold-flags als main. Zonder <code>--err</code>: Bencher post de vergelijking als check/comment (warn). Met <code>--err</code>: run faalt bij threshold-alert (hard fail); toevoegen zodra ruis onder controle is.</p> <p><strong>Robuustheid later:</strong> Overweeg overstap naar json-adapter + BMF file (Criterion JSON of eigen export) zodat wijzigingen in Criterion-output de ingest niet breken.</p> <h3 id=bencher-policy-reports-warn-vs-fail-thresholds>Bencher policy: reports, warn vs fail, thresholds<a class=headerlink href=#bencher-policy-reports-warn-vs-fail-thresholds title="Permanent link">&para;</a></h3> <p><strong>A) Eén report vs meerdere:</strong> Huidige keuze = <strong>meerdere reports</strong> (één per <code>bencher run</code>). Voordeel: duidelijk per workload, thresholds en failures per bench los. Nadeel: twee reports bekijken in Bencher. Alternatief (één report) zou aggregator-bench of BMF/JSON-combinatie vragen; aanbevolen is meerdere reports aanhouden tot PR-gating stabiel is.</p> <p><strong>B) Warn vs fail:</strong> - <strong>perf_pr.yml:</strong> warning-only (geen <code>--err</code>). Bencher post vergelijking als check/comment; bij regressie waarschuwing, merge niet geblokkeerd. - <strong>Later (optioneel):</strong> aparte workflow <code>perf_pr_gate.yml</code> die alleen draait op label <code>perf-gate</code> of “ready for review”, mét <code>--err</code>, zodat regressies de merge blokkeren. Pas toevoegen zodra ruis onder controle is.</p> <p><strong>C) Thresholds per benchmark:</strong> Upper boundary staat nu op Bencher-default (o.a. upper_boundary 0.99). Voor strikte policy: bv. +10% warn, +20% fail; per benchmark overrulen in Bencher UI als één bench inherent noisy is. Thresholds worden van main gecloned naar PR via <code>--start-point-clone-thresholds</code> en <code>--start-point-reset</code>.</p> <p><strong>Exacte PR bencher run-regels (perf_pr.yml, voor diff/warning-policy):</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># PR step 1: store_write_heavy</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>cargo<span class=w> </span>bench<span class=w> </span>-p<span class=w> </span>assay-core<span class=w> </span>--bench<span class=w> </span>store_write_heavy<span class=w> </span><span class=m>2</span>&gt;<span class=p>&amp;</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=w>  </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>-v<span class=w> </span><span class=s2>&quot;Gnuplot not found&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=w>  </span><span class=p>|</span><span class=w> </span>bencher<span class=w> </span>run<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=w>      </span>--project<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_PROJECT</span><span class=s2>&quot;</span><span class=w> </span>--token<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_API_TOKEN</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=w>      </span>--branch<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_HEAD_REF</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=w>      </span>--start-point<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_BASE_REF</span><span class=s2>&quot;</span><span class=w> </span>--start-point-hash<span class=w> </span><span class=s1>&#39;${{ github.event.pull_request.base.sha }}&#39;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=w>      </span>--start-point-clone-thresholds<span class=w> </span>--start-point-reset<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=w>      </span>--testbed<span class=w> </span>ubuntu-latest<span class=w> </span>--adapter<span class=w> </span>rust_criterion<span class=w> </span>--ci-id<span class=w> </span>store_write_heavy<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=w>      </span>--threshold-measure<span class=w> </span>latency<span class=w> </span>--threshold-test<span class=w> </span>t_test<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=w>      </span>--threshold-max-sample-size<span class=w> </span><span class=m>64</span><span class=w> </span>--threshold-upper-boundary<span class=w> </span><span class=m>0</span>.99<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=w>      </span>--github-actions<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_TOKEN</span><span class=s2>&quot;</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=c1># PR step 2: suite_run_worstcase</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a>cargo<span class=w> </span>bench<span class=w> </span>-p<span class=w> </span>assay-cli<span class=w> </span>--bench<span class=w> </span>suite_run_worstcase<span class=w> </span><span class=m>2</span>&gt;<span class=p>&amp;</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a><span class=w>  </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>-v<span class=w> </span><span class=s2>&quot;Gnuplot not found&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a><span class=w>  </span><span class=p>|</span><span class=w> </span>bencher<span class=w> </span>run<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a><span class=w>      </span>--project<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_PROJECT</span><span class=s2>&quot;</span><span class=w> </span>--token<span class=w> </span><span class=s2>&quot;</span><span class=nv>$BENCHER_API_TOKEN</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a><span class=w>      </span>--branch<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_HEAD_REF</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a><span class=w>      </span>--start-point<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_BASE_REF</span><span class=s2>&quot;</span><span class=w> </span>--start-point-hash<span class=w> </span><span class=s1>&#39;${{ github.event.pull_request.base.sha }}&#39;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a><span class=w>      </span>--start-point-clone-thresholds<span class=w> </span>--start-point-reset<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a><span class=w>      </span>--testbed<span class=w> </span>ubuntu-latest<span class=w> </span>--adapter<span class=w> </span>rust_criterion<span class=w> </span>--ci-id<span class=w> </span>suite_run_worstcase<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a><span class=w>      </span>--threshold-measure<span class=w> </span>latency<span class=w> </span>--threshold-test<span class=w> </span>t_test<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-24><a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a><span class=w>      </span>--threshold-max-sample-size<span class=w> </span><span class=m>64</span><span class=w> </span>--threshold-upper-boundary<span class=w> </span><span class=m>0</span>.99<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-25><a id=__codelineno-4-25 name=__codelineno-4-25 href=#__codelineno-4-25></a><span class=w>      </span>--github-actions<span class=w> </span><span class=s2>&quot;</span><span class=nv>$GITHUB_TOKEN</span><span class=s2>&quot;</span>
</span></code></pre></div> <p>(Voor consistent +10% warn / +20% fail: threshold-waarden in Bencher UI of via API aanpassen; voor hard-fail gate: kopie van perf_pr.yml met <code>--err</code> en bv. <code>if: contains(github.event.pull_request.labels.*.name, 'perf-gate')</code>.)</p> <h3 id=summaryjson-velden-phase-store>summary.json-velden (phase + store)<a class=headerlink href=#summaryjson-velden-phase-store title="Permanent link">&para;</a></h3> <p>Vaste velden zodat elke run vergelijkbaar is en regressies automatisch te detecteren:</p> <table> <thead> <tr> <th>Sectie</th> <th>Velden</th> </tr> </thead> <tbody> <tr> <td><strong>Phases</strong></td> <td>ingest_ms, precompute_ms, run_suite_ms, report_ms, total_ms</td> </tr> <tr> <td><strong>Store</strong></td> <td>store_wait_ms, store_write_ms, sqlite_busy_count, txn_batch_size (indien batching)</td> </tr> <tr> <td><strong>Cache</strong></td> <td>cache_hit_count, cache_miss_count (of cache_hit_rate)</td> </tr> <tr> <td><strong>Context</strong></td> <td>db_mode (<code>:memory:</code> of path), parallel, schema_version, assay_version</td> </tr> <tr> <td><strong>DX</strong></td> <td>slowest_tests (top 5), per-test duration_ms in results array (bestaat al)</td> </tr> </tbody> </table> <p>Schema: zie <a href=../architecture/SPEC-PR-Gate-Outputs-v1/ >SPEC-PR-Gate-Outputs-v1</a>; deze velden kunnen als uitbreiding (nieuwe schema_version) worden toegevoegd.</p> <h3 id=ci-cache-blessed-snippet>CI-cache: blessed snippet<a class=headerlink href=#ci-cache-blessed-snippet title="Permanent link">&para;</a></h3> <p><strong>Repo-root (algemeen):</strong></p> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">Cache Assay store</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=w>  </span><span class=nt>id</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">assay-cache</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=w>  </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">actions/cache@v4</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=w>  </span><span class=nt>with</span><span class=p>:</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">.assay</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=w>    </span><span class=nt>key</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">assay-${{ runner.os }}-${{ hashFiles(&#39;**/eval.yaml&#39;, &#39;**/policy.yaml&#39;, &#39;**/traces/*.jsonl&#39;) }}-${{ env.ASSAY_VERSION || &#39;latest&#39; }}</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=w>    </span><span class=nt>restore-keys</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">assay-${{ runner.os }}-</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">Run assay</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=w>  </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">assay ci ...</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">Prove cache hit (job summary / logs)</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=w>  </span><span class=nt>if</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">always()</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a><span class=w>  </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class="p p-Indicator">|</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a><span class=w>    </span><span class=no>echo &quot;cache-hit=${{ steps.assay-cache.outputs.cache-hit }}&quot;</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a><span class=w>    </span><span class=no>echo &quot;cache-hit=${{ steps.assay-cache.outputs.cache-hit }}&quot; &gt;&gt; &quot;$GITHUB_STEP_SUMMARY&quot;</span>
</span></code></pre></div> <p><strong>Subdir (bijv. baseline-gate):</strong> Gebruik <code>path</code> op de betreffende directory (bijv. <code>examples/baseline-gate/.eval</code> en <code>examples/baseline-gate/.assay</code>) en pas de <code>key</code> aan op de bestanden in die dir. Zie <code>.github/workflows/baseline-gate-demo.yml</code> voor een werkend voorbeeld; daar wordt <strong>cache-hit</strong> in de job summary gelogd.</p> <p><strong>Eis:</strong> In CI logs én in de job summary moet <strong>cache-hit=true</strong> of <strong>cache-hit=false</strong> zichtbaar zijn.</p> <p>Invalidatie: bij wijziging in eval/policy/traces of assay version. Documenteer: wat wel/niet gecached wordt. <strong>In CI:</strong> log <strong>cache-hit</strong> in job summary (bijv. <code>echo "cache-hit=${{ steps.cache.outputs.cache-hit }}"</code> of in job summary step) zodat warm-cache claims feitelijk onderbouwd zijn.</p> <h3 id=ci-cache-voor-perf-jobs>CI cache voor perf jobs<a class=headerlink href=#ci-cache-voor-perf-jobs title="Permanent link">&para;</a></h3> <p>Voor een <strong>complete performance assessment</strong> moet de <strong>perf-job</strong> (Criterion benches) ook cache + cache-hit gebruiken, niet alleen baseline-gate-demo:</p> <ul> <li><strong>Blessed cache-strategie voor perf:</strong> Cache <code>target/</code> (rust-cache doet dit al) zodat <code>cargo bench</code> sneller draait; optioneel: cache <code>.assay/</code> of een perf-fixture dir als de perf-job e2e (Hyperfine) draait. <strong>Norm:</strong> Waar cache leeft: repo-root <code>.assay/</code> voor assay-run output; <code>target/</code> voor build/bench; subdir (bijv. <code>examples/baseline-gate/.assay</code>) voor workflow-specifieke runs. Wat je cached: DB + embeddings-cache + wat de key invalideert (eval/policy/trace hash).</li> <li><strong>Perf-job: cache-hit in job summary:</strong> In de perf-job (ci.yml) <strong>altijd</strong> cache-hit loggen in de job summary, zodat warm-run claims verifieerbaar zijn. Zonder dit is “warm cache” niet bewijsbaar.</li> </ul> <p><strong>Huidige stand:</strong> baseline-gate-demo.yml cached en logt cache-hit. De Criterion-perf-job in ci.yml gebruikt Swatinem/rust-cache (target/); <strong>aanbevolen:</strong> voeg een stap toe die cache-hit (van rust-cache of een assay-perf cache) in de job summary logt.</p> <hr> <h2 id=perf-gate-policy-optioneel>Perf gate policy (optioneel)<a class=headerlink href=#perf-gate-policy-optioneel title="Permanent link">&para;</a></h2> <p>Een concrete “perf gate”-policy (bijv. <strong>“p95 worstcase mag max +10% regressen”</strong>) die realistisch is voor GitHub runners en niet elke PR random rood maakt, kan apart voorgesteld worden. Zodra baseline (20× worstcase file-backed, median + p95) en CI cache-hit vaststaan, is zo’n gate in te bouwen.</p> <hr> <h2 id=verwijzingen>Verwijzingen<a class=headerlink href=#verwijzingen title="Permanent link">&para;</a></h2> <ul> <li><a href=../architecture/ADR-019-PR-Gate-2026-SOTA/#p03-store-performance-wal--single-writer-batching--bounded-queue>ADR-019 P0.3</a></li> <li><a href=DX-IMPLEMENTATION-PLAN.md>DX-IMPLEMENTATION-PLAN</a> (o.a. slowest 5, cache hit rate, phase timings in summary)</li> <li><a href=../architecture/SPEC-PR-Gate-Outputs-v1/ >SPEC-PR-Gate-Outputs-v1</a> (summary.json schema)</li> <li><a href=../concepts/cache/ >concepts/cache.md</a></li> <li><a href=https://github.com/bheisler/criterion.rs>Criterion</a>, <a href=https://github.com/sharkdp/hyperfine>Hyperfine</a>, <a href=https://nnethercote.github.io/perf-book/ >Rust Performance Book</a>, <a href=https://bencher.dev/ >Bencher</a> (continuous benchmarking, <a href=https://bencher.dev/docs/how-to/github-actions/ >GitHub Actions</a>)</li> </ul> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 Assay </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/Rul1an/assay target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/assay_dev target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://discord.gg/assay target=_blank rel=noopener title=discord.gg class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485.065 485.065 0 0 0 404.081 32.03a1.816 1.816 0 0 0-1.923.91 337.461 337.461 0 0 0-14.9 30.6 447.848 447.848 0 0 0-134.426 0 309.541 309.541 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.689 483.689 0 0 0-119.688 37.107 1.712 1.712 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.016 2.016 0 0 0 .765 1.375 487.666 487.666 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348.2 348.2 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321.173 321.173 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251.047 251.047 0 0 0 9.109-7.137 1.819 1.819 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.812 1.812 0 0 1 1.924.233 234.533 234.533 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.407 301.407 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391.055 391.055 0 0 0 30.014 48.815 1.864 1.864 0 0 0 2.063.7A486.048 486.048 0 0 0 610.7 405.729a1.882 1.882 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541ZM222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241Zm195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241Z"/></svg> </a> <a href=https://getassay.dev target=_blank rel=noopener title=getassay.dev class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5 20h14v-2H5m14-9h-4V3H9v6H5l7 7 7-7Z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["navigation.instant", "navigation.instant.prefetch", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.top", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.tabs.link", "toc.follow"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../assets/javascripts/bundle.fe8b6f2b.min.js></script> </body> </html>